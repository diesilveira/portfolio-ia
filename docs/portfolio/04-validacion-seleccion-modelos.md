# TA4 - Validaci칩n y Selecci칩n de Modelos

## Resumen de la Tarea

Esta tarea consisti칩 en implementar t칠cnicas avanzadas de validaci칩n cruzada y selecci칩n de modelos para evaluar la estabilidad y rendimiento de diferentes algoritmos de machine learning. El objetivo principal fue comprender la importancia de la validaci칩n rigurosa, comparar m칠todos de validaci칩n cruzada, y seleccionar el mejor modelo bas치ndose en criterios de rendimiento y estabilidad.

### Metodolog칤a

1. **Dataset utilizado**: Student Dropout and Academic Success (UCI ML Repository)
   - 4,424 estudiantes con 36 caracter칤sticas
   - Problema multiclase: Dropout (32.1%), Enrolled (17.9%), Graduate (49.9%)

2. **T칠cnicas de validaci칩n cruzada**:
   - **KFold**: Divisi칩n simple en 5 partes
   - **StratifiedKFold**: Mantiene proporci칩n de clases en cada fold

3. **Comparaci칩n de modelos**:
   - Logistic Regression con StandardScaler
   - Ridge Classifier con regularizaci칩n L2
   - Random Forest (ensemble method)

4. **M칠tricas de evaluaci칩n**:
   - F1-score weighted para manejar clases desbalanceadas
   - An치lisis de estabilidad mediante desviaci칩n est치ndar
   - Visualizaci칩n comparativa de distribuciones

### Dataset: Student Dropout and Academic Success

- **Estudiantes**: 4,424 registros
- **Caracter칤sticas**: 36 variables (edad al inscribirse, calificaciones previas, estado civil, etc.)
- **Clases**: Dropout (0), Enrolled (1), Graduate (2)
- **Distribuci칩n**: Desbalanceada con predominio de graduados (49.9%)

## Resultados de Validaci칩n Cruzada

### Comparaci칩n KFold vs StratifiedKFold

**KFold (5 splits):**
- Scores individuales: [0.742, 0.745, 0.755, 0.762, 0.765]
- **Resultado**: 75.36% 췀 0.89%

**StratifiedKFold (5 splits):**
- Scores individuales: [0.755, 0.746, 0.754, 0.749, 0.751]
- **Resultado**: 75.09% 췀 0.32%

**Conclusi칩n**: StratifiedKFold es **M츼S ESTABLE** (menor variabilidad: 0.32% vs 0.89%)

### Competencia de Modelos

**Resultados con 5-Fold Cross-Validation (F1-weighted):**

1. **游끥 Random Forest**: 74.94% 췀 0.41% (GANADOR)
2. **Logistic Regression**: 74.42% 췀 0.71%
3. **Ridge Classifier**: 70.96% 췀 0.47%

**An치lisis de estabilidad**: Todos los modelos son **MUY ESTABLES** (std < 0.02)

![Gr치ficos de Validaci칩n Cruzada y Comparaci칩n de Modelos](Practica 4 graficas.png)

Los gr치ficos muestran la distribuci칩n de scores y la comparaci칩n visual entre los diferentes m칠todos de validaci칩n cruzada y modelos evaluados.

## Parte 1: Definiciones de Cross-Validation

### Completa las definiciones:

**Cross-Validation**: T칠cnica que divide los datos en **m칰ltiples** partes para entrenar y evaluar m칰ltiples veces.

**Accuracy promedio**: La **estimaci칩n** de rendimiento esperado en datos nuevos.

**Desviaci칩n est치ndar**: Indica qu칠 tan **estable** es el modelo entre diferentes divisiones de datos.

**StratifiedKFold**: Mantiene la **proporci칩n** de clases en cada fold, especialmente importante en datasets desbalanceados.

### Interpretaci칩n:
- **Cross-validation 5-fold**: Dividimos en 5 partes, entrenamos 5 veces diferentes
- **75.09% 췀 0.32%**: Rendimiento esperado con alta confianza
- **Baja desviaci칩n (0.32%)**: Modelo muy consistente entre diferentes divisiones

## Parte 2: 쮺u치ndo usar cada m칠todo?

### Completa la gu칤a de decisi칩n:

GridSearchCV cuando se tiene pocos hiperpar치metros y suficiente tiempo de c칩mputo.

RandomizedSearchCV cuando tienes muchos hiperpar치metros o tiempo** limitado.

Pipeline + SearchCV siempre previene data leakage autom치ticamente.

cross_val_score en el resultado final valida que la optimizaci칩n no caus칩** overfitting.

### Aplicaci칩n pr치ctica:
- **GridSearchCV**: Ideal para optimizar 2-3 hiperpar치metros con b칰squeda exhaustiva
- **RandomizedSearchCV**: Mejor para Random Forest con muchos par치metros (n_estimators, max_depth, etc.)
- **Pipeline**: En el TA4 previno que StandardScaler viera datos de test durante CV
- **cross_val_score**: Confirm칩 que Random Forest no se sobreajust칩 durante la selecci칩n

## Parte 3: 쯇or qu칠 es importante la explicabilidad?

### Completa las razones:

**Confianza**: Los educadores necesitan **entender** por qu칠 el modelo predice abandono.

**Intervenciones**: Knowing las caracter칤sticas importantes permite crear **estrategias** espec칤ficas.

**Bias detection**: La explicabilidad ayuda a detectar **sesgos** en el modelo.

**Regulaciones**: Muchos contextos requieren modelos **interpretables** por ley.

**Mejora continua**: Entender el modelo ayuda a **mejorar** futuras versiones.

## Parte 4: Preguntas de Reflexi칩n

### 쯈u칠 es data leakage y por qu칠 es peligroso?

**Respuesta**: Data leakage ocurre cuando informaci칩n que no deber칤a estar disponible durante el entrenamiento "se filtra" al modelo, creando una ventaja artificial que no existir치 en producci칩n.

### 쮺u치ndo usar KFold vs StratifiedKFold?

**KFold cuando:**
- Problemas de regresi칩n (no hay clases)
- Datasets muy grandes donde la proporci칩n se mantiene naturalmente

**StratifiedKFold cuando:**
- **Clases desbalanceadas**
- **Clases minoritarias** que podr칤an desaparecer en algunos folds
- **Siempre en clasificaci칩n** como pr치ctica defensiva

En esta tarea: StratifiedKFold fue esencial porque con solo 17.9% de estudiantes "Enrolled", KFold podr칤a crear folds sin esta clase.

### 쮺칩mo interpretar "75.09% 췀 0.32%" en cross-validation?

**Interpretaci칩n completa:**
- **75.09%**: Rendimiento promedio esperado en datos nuevos
- **췀 0.32%**: Intervalo de confianza - el modelo es muy estable
- **Rango**: Entre 74.77% y 75.41% en el 68% de los casos
- **Estabilidad**: Desviaci칩n muy baja indica modelo robusto

**Comparaci칩n**: 75.09% 췀 0.32% es mucho mejor que 75.36% 췀 0.89% porque la menor variabilidad indica mayor confiabilidad.

### 쯇or qu칠 Random Forest no necesita StandardScaler?

**Respuesta**: Random Forest est치 basado en **치rboles de decisi칩n**, que toman decisiones mediante **comparaciones ordinales** (mayor/menor) en lugar de **distancias euclidianas**.

Por eso Random Forest no incluye StandardScaler en su Pipeline, mientras que Logistic Regression y Ridge s칤 lo necesitan.

### En diagn칩stico m칠dico, 쯣refieres 98% accuracy pero inestable, o 95% accuracy pero muy estable?

**Respuesta**: **95% accuracy pero muy estable**

**Justificaci칩n:**
- **Confiabilidad**: Un modelo que var칤a mucho genera desconfianza

- **Decisiones consistentes**: 

- **Implementaci칩n**: Un modelo estable es m치s f치cil de mantener y actualizar

- **Riesgo**: 3% menos de accuracy es preferible a predicciones err치ticas


## Conclusiones

El TA4 demostr칩 exitosamente:

1. **StratifiedKFold es superior** para datasets desbalanceados (0.32% vs 0.89% de variabilidad)
2. **Random Forest gan칩** la competencia con 74.94% 췀 0.41% de F1-score
3. **Todos los modelos fueron estables** (std < 0.02), indicando validaci칩n robusta
4. **Los Pipelines previenen data leakage** autom치ticamente en validaci칩n cruzada
5. **La estabilidad es tan importante como el rendimiento** en aplicaciones reales

Los resultados confirman que una validaci칩n rigurosa es fundamental para seleccionar modelos confiables que funcionen bien en producci칩n, especialmente en contextos sensibles como la educaci칩n donde las decisiones afectan el futuro de los estudiantes.
