# TA4 - Validaci贸n y Selecci贸n de Modelos

## Resumen de la Tarea

Esta tarea consisti贸 en implementar t茅cnicas avanzadas de validaci贸n cruzada y selecci贸n de modelos para evaluar la estabilidad y rendimiento de diferentes algoritmos de machine learning. El objetivo principal fue comprender la importancia de la validaci贸n rigurosa, comparar m茅todos de validaci贸n cruzada, y seleccionar el mejor modelo bas谩ndose en criterios de rendimiento y estabilidad.

### Metodolog铆a

1. **Dataset utilizado**: Student Dropout and Academic Success (UCI ML Repository)
   - 4,424 estudiantes con 36 caracter铆sticas
   - Problema multiclase: Dropout (32.1%), Enrolled (17.9%), Graduate (49.9%)

2. **T茅cnicas de validaci贸n cruzada**:
   - **KFold**: Divisi贸n simple en 5 partes
   - **StratifiedKFold**: Mantiene proporci贸n de clases en cada fold

3. **Comparaci贸n de modelos**:
   - Logistic Regression con StandardScaler
   - Ridge Classifier con regularizaci贸n L2
   - Random Forest (ensemble method)

4. **M茅tricas de evaluaci贸n**:
   - F1-score weighted para manejar clases desbalanceadas
   - An谩lisis de estabilidad mediante desviaci贸n est谩ndar
   - Visualizaci贸n comparativa de distribuciones

### Dataset: Student Dropout and Academic Success

- **Estudiantes**: 4,424 registros
- **Caracter铆sticas**: 36 variables (edad al inscribirse, calificaciones previas, estado civil, etc.)
- **Clases**: Dropout (0), Enrolled (1), Graduate (2)
- **Distribuci贸n**: Desbalanceada con predominio de graduados (49.9%)

## Resultados de Validaci贸n Cruzada

### Comparaci贸n KFold vs StratifiedKFold

**KFold (5 splits):**

- Scores individuales: [0.742, 0.745, 0.755, 0.762, 0.765]
- **Resultado**: 75.36% 卤 0.89%

**StratifiedKFold (5 splits):**

- Scores individuales: [0.755, 0.746, 0.754, 0.749, 0.751]
- **Resultado**: 75.09% 卤 0.32%

**Conclusi贸n**: StratifiedKFold es **MS ESTABLE** (menor variabilidad: 0.32% vs 0.89%)

### Competencia de Modelos

**Resultados con 5-Fold Cross-Validation (F1-weighted):**

1. ** Random Forest**: 74.94% 卤 0.41% (GANADOR)
2. **Logistic Regression**: 74.42% 卤 0.71%
3. **Ridge Classifier**: 70.96% 卤 0.47%

**An谩lisis de estabilidad**: Todos los modelos son **MUY ESTABLES** (std < 0.02)

![Gr谩ficos de Validaci贸n Cruzada y Comparaci贸n de Modelos](Practica 4 graficas.png)

Los gr谩ficos muestran la distribuci贸n de scores y la comparaci贸n visual entre los diferentes m茅todos de validaci贸n cruzada y modelos evaluados.

## Parte 1: Definiciones de Cross-Validation

**Cross-Validation**: T茅cnica que divide los datos en **m煤ltiples** partes para entrenar y evaluar m煤ltiples veces.

**Accuracy promedio**: La **estimaci贸n** de rendimiento esperado en datos nuevos.

**Desviaci贸n est谩ndar**: Indica qu茅 tan **estable** es el modelo entre diferentes divisiones de datos.

**StratifiedKFold**: Mantiene la **proporci贸n** de clases en cada fold, especialmente importante en datasets desbalanceados.

### Interpretaci贸n

- **Cross-validation 5-fold**: Dividimos en 5 partes, entrenamos 5 veces diferentes
- **75.09% 卤 0.32%**: Rendimiento esperado con alta confianza
- **Baja desviaci贸n (0.32%)**: Modelo muy consistente entre diferentes divisiones

## Parte 2: 驴Cu谩ndo usar cada m茅todo?

GridSearchCV cuando se tiene pocos hiperpar谩metros y suficiente tiempo de c贸mputo.

RandomizedSearchCV cuando tienes muchos hiperpar谩metros o tiempo** limitado.

Pipeline + SearchCV siempre previene data leakage autom谩ticamente.

cross_val_score en el resultado final valida que la optimizaci贸n no caus贸** overfitting.

### Aplicaci贸n pr谩ctica

- **GridSearchCV**: Ideal para optimizar 2-3 hiperpar谩metros con b煤squeda exhaustiva
- **RandomizedSearchCV**: Mejor para Random Forest con muchos par谩metros (n_estimators, max_depth, etc.)
- **Pipeline**: En el TA4 previno que StandardScaler viera datos de test durante CV
- **cross_val_score**: Confirm贸 que Random Forest no se sobreajust贸 durante la selecci贸n

## Parte 3: 驴Por qu茅 es importante la explicabilidad?

La explicabilidad es crucial porque los educadores necesitan entender por qu茅 el modelo predice abandono para generar confianza, conocer las caracter铆sticas importantes permite crear estrategias de intervenci贸n espec铆ficas, ayuda a detectar sesgos en el modelo, muchos contextos requieren modelos interpretables por ley, y entender el modelo facilita la mejora continua de futuras versiones.

## Parte 4: Preguntas de Reflexi贸n

### 驴Qu茅 es data leakage y por qu茅 es peligroso?

Data leakage ocurre cuando informaci贸n que no deber铆a estar disponible durante el entrenamiento "se filtra" al modelo, creando una ventaja artificial que no existir谩 en producci贸n.

### 驴Cu谩ndo usar KFold vs StratifiedKFold?

KFold es apropiado para problemas de regresi贸n donde no hay clases o en datasets muy grandes donde la proporci贸n se mantiene naturalmente, mientras que StratifiedKFold debe usarse cuando hay clases desbalanceadas, clases minoritarias que podr铆an desaparecer en algunos folds, y como pr谩ctica defensiva siempre en clasificaci贸n. En esta tarea, StratifiedKFold fue esencial porque con solo 17.9% de estudiantes "Enrolled", KFold podr铆a crear folds sin esta clase minoritaria.

### 驴C贸mo interpretar "75.09% 卤 0.32%" en cross-validation?

El valor 75.09% representa el rendimiento promedio esperado en datos nuevos, mientras que 卤 0.32% es el intervalo de confianza que indica que el modelo es muy estable, con un rango entre 74.77% y 75.41% en el 68% de los casos. Esta desviaci贸n muy baja indica un modelo robusto. Por ejemplo, 75.09% 卤 0.32% es mucho mejor que 75.36% 卤 0.89% porque la menor variabilidad indica mayor confiabilidad.

### 驴Por qu茅 Random Forest no necesita StandardScaler?

Random Forest est谩 basado en 谩rboles de decisi贸n que toman decisiones mediante comparaciones ordinales (mayor/menor) en lugar de distancias euclidianas, por lo que no necesita StandardScaler en su Pipeline, mientras que modelos como Logistic Regression y Ridge s铆 lo requieren porque calculan distancias y son sensibles a la escala de las variables.

### En diagn贸stico m茅dico, 驴prefieres 98% accuracy pero inestable, o 95% accuracy pero muy estable?

Prefiero 95% accuracy pero muy estable. Un modelo que var铆a mucho genera desconfianza en los profesionales m茅dicos, las decisiones consistentes son cruciales para tratamientos que afectan vidas humanas, un modelo estable es m谩s f谩cil de mantener y actualizar en producci贸n, y 3% menos de accuracy es preferible a predicciones err谩ticas que podr铆an cambiar el diagn贸stico del mismo paciente en diferentes momentos.

## Conclusiones

En esta tarea demostramos que StratifiedKFold es superior para datasets desbalanceados (0.32% vs 0.89% de variabilidad), que Random Forest gan贸 la competencia con 74.94% 卤 0.41% de F1-score, que todos los modelos fueron estables (std < 0.02) indicando validaci贸n robusta, que los Pipelines previenen data leakage autom谩ticamente en validaci贸n cruzada, y que la estabilidad es tan importante como el rendimiento en aplicaciones reales. Los resultados confirman que una validaci贸n rigurosa es fundamental para seleccionar modelos confiables que funcionen bien en producci贸n, especialmente en contextos sensibles como la educaci贸n donde las decisiones afectan el futuro de los estudiantes.
