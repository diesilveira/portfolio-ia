#  Vertex AI Pipelines - Qwik Start

## 1. Resumen del Lab

Este lab vimos com automatizar y reproducir workflows de ML usando Vertex AI Pipelines

- **Automatizaci贸n de workflows ML**: Convertir procesos manuales en pipelines reproducibles y ejecutables
- **Gesti贸n de dependencias**: Cada paso del pipeline es un contenedor independiente con sus propias dependencias
- **Reproducibilidad**: Trackear inputs y outputs de cada paso para garantizar resultados consistentes
- **Integraci贸n con servicios de Vertex AI**: Usar componentes pre-construidos para interactuar con AutoML, datasets, modelos y endpoints

## 2. Tareas principales realizadas

Configuraci贸n inicial del entorno:
El primer paso consisti贸 en instalar las librer铆as necesarias: el Kubeflow Pipelines SDK y Google Cloud Pipeline Components. Luego configur茅 el proyecto ID y el bucket de Cloud Storage, definiendo las rutas donde se almacenar铆an los artefactos generados por el pipeline.

Creaci贸n de un pipeline sencilo de 3 componentes:
Constru铆 un pipeline simple de tres componentes. Comenc茅 creando componentes personalizados usando decoradores `@component`, donde cada componente toma inputs y produce outputs espec铆ficos. Luego conect茅 estos componentes en un pipeline usando el decorador `@dsl.pipeline`. Una vez definido el pipeline, lo compil茅 a formato JSON, lo ejecut茅 en Vertex AI Pipelines y monitore茅 su progreso, visualizando los resultados finales en la consola de Google Cloud.

![Pipeline inicial](16-imagenes/pipeline1.png)

Construcci贸n de un pipeline ML end-to-end**

El siguiente paso fue construir un pipeline completo de machine learning. Cre茅 un componente personalizado para evaluaci贸n de modelos que calcula m茅tricas de clasificaci贸n y decide si el modelo cumple con los umbrales establecidos. Complement茅 esto con componentes pre-construidos de Google Cloud Pipeline Components: `TabularDatasetCreateOp` para crear datasets tabulares desde BigQuery, `AutoMLTabularTrainingJobRunOp` para entrenar modelos AutoML de clasificaci贸n, y `ModelDeployOp` para desplegar modelos a endpoints de Vertex AI. Implement茅 l贸gica condicional usando `dsl.Condition` para que el deployment solo ocurra si las m茅tricas superan ciertos umbrales. Durante la ejecuci贸n, visualic茅 m茅tricas como curvas ROC y matrices de confusi贸n en la interfaz de Vertex AI Pipelines, y utilic茅 lineage tracking para rastrear todos los artefactos creados durante el proceso.

![Pipeline e2e](16-imagenes/e2e.png)

### 3. Conceptos/t茅cnicas incorporadas

Componentes como contenedores independientes:
Comprend铆 que cada componente funciona como un contenedor independiente con su propia imagen base y dependencias espec铆ficas. Los componentes se comunican mediante inputs y outputs. Esta arquitectura permite desarrollar componentes de forma independiente y reutilizarlos en diferentes pipelines.

Pipeline como grafo de ejecuci贸n:
Aprend铆 que los pipelines se definen como grafos de ejecuci贸n donde se especifican las dependencias entre componentes. Los outputs de un componente alimentan directamente los inputs de otros, creando un flujo de datos estructurado. El sistema maneja autom谩ticamente la ejecuci贸n paralela cuando es posible, optimizando el tiempo total de ejecuci贸n del pipeline.

### 4. Conclusiones

Lo m谩s valioso de este lab fue comprender c贸mo automatizar completamente el ciclo de ML, desde la creaci贸n del dataset hasta el deployment del modelo.
Cada paso del pipeline es independiente, lo que facilita el debugging al permitir identificar exactamente d贸nde falla el proceso, simplifica la optimizaci贸n al poder mejorar un paso sin afectar otros componentes, y promueve la reutilizaci贸n de componentes en diferentes pipelines.
