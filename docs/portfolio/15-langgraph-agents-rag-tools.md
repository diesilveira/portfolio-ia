# TA15 - Agentes con LangGraph: RAG, Tools y Memoria Conversacional

## Resumen de la Tarea

En esta tarea exploramos la construcci√≥n de **agentes conversacionales aut√≥nomos** utilizando **LangGraph**, un framework que permite orquestar modelos de lenguaje (LLMs) con herramientas externas y gesti√≥n de estado. El objetivo principal fue dise√±ar un agente capaz de mantener conversaciones multi-turn, utilizar herramientas especializadas (RAG para b√∫squeda de conocimiento y otras tools auxiliares), y gestionar memoria conversacional mediante res√∫menes incrementales.

### Metodolog√≠a

La metodolog√≠a consisti√≥ en una construcci√≥n incremental hasta un sistema completo con interfaz de usuario. Comenzamos definiendo un `AgentState` tipado con TypedDict que viaja por todo el grafo, conteniendo mensajes y un resumen opcional. Luego implementamos un grafo b√°sico con LangGraph que conecta un nodo `assistant` (que invoca el LLM) con transiciones simples desde START hasta END.

El siguiente paso fue integrar **RAG como tool reutilizable**, creando un vector store FAISS con embeddings de OpenAI sobre un conocimiento espec√≠fico (Federaci√≥n Uruguaya de Ajedrez). Implementamos m√∫ltiples tools incluyendo `rag_search` para b√∫squeda sem√°ntica, `get_order_status` para consultas de pedidos ficticios, y `get_utc_time` para obtener la hora actual.

La orquestaci√≥n se logr√≥ mediante un grafo con flujo condicional, permitiendo que el agente decida aut√≥nomamente cu√°ndo usar herramientas bas√°ndose en el contexto. Agregamos un nodo `memory` que genera res√∫menes incrementales de la conversaci√≥n, actualiz√°ndose despu√©s de cada uso de tools para mantener contexto sin acumular todo el historial. Finalmente, armamos el bot completo en una interfaz **Gradio** con chat interactivo, visualizaci√≥n de tools utilizados, y gesti√≥n de estado persistente entre turnos.

Durante toda la pr√°ctica utilizamos `gpt-5-mini` y `gpt-5-nano` de OpenAI, con LangSmith habilitado para tracing y observabilidad de las ejecuciones del grafo.

## Implementaci√≥n y Resultados

### Parte 1: Estado del Agente (AgentState)

Definimos un `AgentState` tipado que viaja por todos los nodos del grafo, compuesto principalmente por una lista de `messages` (que acumula el historial de mensajes) y un `summary` opcional que mantiene un resumen incremental de la conversaci√≥n gestionado por el nodo de memoria. Esta estructura permite que cada componente del grafo acceda tanto al historial como al contexto sintetizado, facilitando decisiones informadas sobre qu√© herramientas utilizar en cada paso.

### Parte 2: Grafo B√°sico con Assistant

El primer paso consisti√≥ en implementar un grafo b√°sico lineal que conecta el punto de inicio (`START`) directamente con un nodo `assistant` y finaliza en `END`.

**Prueba inicial:** Al consultar "¬øqu√© es un enroque?" con un system prompt que define al agente como instructor de ajedrez, el modelo respondi√≥ correctamente en formato JSON estructurado:

```json
{
  "title": "Enroque (castling)",
  "description": "El enroque es un movimiento que involucra al rey y a una torre. El rey se desplaza dos casillas hacia la torre y ..."
}
```

### Parte 3: RAG como Tool Reutilizable

Para integrar la recuperaci√≥n de informaci√≥n (RAG), creamos un √≠ndice vectorial utilizando FAISS y embeddings de OpenAI sobre documentos de la Federaci√≥n Uruguaya de Ajedrez. Definimos una funci√≥n decorada con `@tool` llamada `rag_search`, la cual realiza b√∫squedas de similitud en el √≠ndice y devuelve el contexto relevante. Es fundamental redactar un docstring claro ("devuelve informaci√≥n sobre la federaci√≥n de ajedrez del uruguay"), ya que el LLM utiliza esta descripci√≥n para decidir cu√°ndo invocar la herramienta durante la conversaci√≥n.

### Parte 4: Tools Adicionales

Adem√°s de la b√∫squeda sem√°ntica, implementamos herramientas auxiliares para demostrar la versatilidad del sistema en el manejo de diferentes tipos de tareas. Creamos una tool llamada `get_order_status` que permite consultar el estado de pedidos ficticios (como "ABC123" o "XYZ999") accediendo a un diccionario simulado, y otra tool `get_utc_time` que proporciona la hora actual en formato ISO. Estas funciones simples ilustran c√≥mo el agente puede interactuar con sistemas deterministas externos m√°s all√° de la recuperaci√≥n de informaci√≥n.

### Parte 5: Orquestaci√≥n LLM + Tools

El patr√≥n arquitect√≥nico clave es el flujo condicional que permite al agente decidir aut√≥nomamente cu√°ndo usar herramientas. Para lograr esto, creamos una lista de herramientas (`tools`) y vinculamos el LLM con ellas usando `.bind_tools()`, lo que permite al modelo emitir llamadas a funciones.

El grafo se construye con dos nodos principales: `assistant`, encargado del razonamiento y la generaci√≥n de respuestas, y `tools`, que ejecuta las acciones solicitadas. La l√≥gica de enrutamiento se implementa mediante una funci√≥n condicional (`route_from_assistant`) que examina el √∫ltimo mensaje del asistente; si contiene llamadas a herramientas, desv√≠a el flujo hacia el nodo `tools`, creando un bucle que retorna al asistente con los resultados. En caso contrario, si el asistente genera una respuesta final directa, el flujo termina en `END`.

**Flujo de ejecuci√≥n:**

1. `START` ‚Üí `assistant`: El LLM analiza la pregunta
2. Si necesita tools: `assistant` ‚Üí `tools` ‚Üí `assistant` (bucle)
3. Si no necesita tools o ya tiene la respuesta: `assistant` ‚Üí `END`

**Ejemplo de conversaci√≥n:**

**Usuario:** "Hola, ¬øqu√© es el ajedrez? hay alguna federaci√≥n en uruguay? quien es el presidente de la FUA?"

**Agente (con tool call a rag_search):**

```text
Hola ‚Äî te respondo en breve:

1) ¬øQu√© es el ajedrez?
- El ajedrez es un juego/deporte de mesa y estrategia entre dos jugadores, que se juega en un tablero de 8x8 casillas...

2) ¬øHay alguna federaci√≥n en Uruguay?
- S√≠. El organismo rector del ajedrez en Uruguay es la Federaci√≥n Uruguaya de Ajedrez (FUA). La FUA organiza los campeonatos nacionales, regula torneos, y representa a Uruguay ante la FIDE y otros organismos.

3) ¬øQui√©n es el presidente de la FUA?
- No tengo a mano un nombre verificado y actualizado en este momento...
```

**Usuario:** "Us√° tu base de conocimiento y decime en que estado se encuentra la orden ABC123."

**Agente (con tool call a get_order_status):**

```text
La orden ABC123 est√°: En preparaci√≥n.

Esto normalmente significa que el pedido est√° siendo procesado/picked y embalado y a√∫n no ha sido enviado...
```

El agente correctamente identific√≥ que la primera pregunta requer√≠a `rag_search` (informaci√≥n sobre ajedrez/FUA) y la segunda `get_order_status` (consulta de pedido), demostrando razonamiento contextual.

### Parte 6: Memoria Conversacional con Summary

Para abordar el problema de la ventana de contexto limitada en conversaciones largas, implementamos un nodo de memoria (`memory_node`) que genera res√∫menes incrementales. Este nodo utiliza un modelo `gpt-5-mini` para condensar la informaci√≥n clave de los √∫ltimos 6 mensajes y combinarla con el resumen previo, generando una lista concisa de "bullets" que sintetizan lo discutido hasta el momento.

El flujo del grafo se actualiz√≥ para incluir este nodo, de modo que la secuencia de ejecuci√≥n se convierte en `START ‚Üí assistant ‚Üí (tools ‚Üí memory ‚Üí assistant)* ‚Üí END`.

![flujo bot](15-imagenes/flujo.png)

Esto asegura que el resumen se actualice autom√°ticamente despu√©s de cada uso de herramientas, capturando as√≠ las interacciones cr√≠ticas donde el agente ha buscado informaci√≥n externa, sin necesidad de almacenar la totalidad del historial de mensajes.

**Ejemplo de summary generado:**

Despu√©s de preguntar "¬øqui√©n es el presidente de la FUA?" y usar `rag_search`:

```text
- El usuario pregunt√≥ qui√©n es el presidente de la FUA.
- El asistente se√±al√≥ que la FUA es el organismo rector del ajedrez en Uruguay y mencion√≥ su afiliaci√≥n a la FIDE.
- No se proporcion√≥ el nombre del presidente; las respuestas fueron parciales y repetidas.
```

Tras una segunda pregunta "¬øY en qu√© a√±o se fund√≥ la FUA?":

```text
- El usuario pregunt√≥ qui√©n es el presidente de la FUA; el asistente indic√≥ que la FUA es el organismo rector del ajedrez en Uruguay y est√° afiliada a la FIDE, pero no dio el nombre del presidente.
- El asistente se√±al√≥ no tener informaci√≥n actualizada sobre el presidente y ofreci√≥ intentar buscarlo.
- El usuario pregunt√≥ luego en qu√© a√±o se fund√≥ la FUA; las respuestas del asistente fueron parciales y repetidas, sin proporcionar la fecha.
```

El summary captura la **evoluci√≥n de la conversaci√≥n** de manera eficiente.

### Parte 7: Interfaz de Usuario con Gradio

El sistema completo se integr√≥ en una interfaz web interactiva desarrollada con Gradio, lo que permite a los usuarios conversar con el agente en tiempo real. Esta implementaci√≥n gestiona el estado de la conversaci√≥n de forma persistente entre turnos y proporciona feedback visual inmediato, mostrando no solo el historial del chat sino tambi√©n qu√© herramientas espec√≠ficas ("tools") fueron invocadas por el agente para generar cada respuesta. Esto ofrece una experiencia transparente donde se puede verificar cu√°ndo el sistema utiliza su base de conocimiento (RAG) o sus utilidades auxiliares.

![gradio1](15-imagenes/gradio1.png)

![gradio2](15-imagenes/gradio2.png)

**Caracter√≠sticas de la UI:**

- **Chat interactivo:** Conversaci√≥n persistente con formato amigable
- **Visualizaci√≥n de tools:** Muestra qu√© herramientas us√≥ el agente en cada respuesta
- **Estado persistente:** El `agent_state` se mantiene entre turnos mediante `gr.State()`

La aplicaci√≥n final permite interactuar con el agente de forma natural, consultar informaci√≥n sobre ajedrez (mediante RAG), verificar pedidos ficticios, y observar en tiempo real qu√© herramientas est√° utilizando el agente para responder cada pregunta.

## Preguntas de Reflexi√≥n

### ¬øD√≥nde ves expl√≠citamente que hay un estado que viaja por el grafo?

El estado viaja expl√≠citamente en la definici√≥n de los nodos y las aristas del grafo. Se observa en la creaci√≥n del `StateGraph`, que est√° tipado con el esquema `AgentState`, y en las firmas de las funciones de cada nodo, que reciben el estado completo y devuelven actualizaciones parciales. Adem√°s, el uso de reducers como `operator.add` define c√≥mo se combinan estas actualizaciones, permitiendo que el historial de mensajes y el resumen fluyan y evolucionen a trav√©s de toda la ejecuci√≥n, desde el inicio hasta el final.

### ¬øQu√© ventaja tiene guardar un summary en vez de todo el historial?

Guardar un resumen en lugar de todo el historial ofrece ventajas significativas en eficiencia y rendimiento. Reduce dr√°sticamente el consumo de tokens, lo que disminuye costos y latencia, permitiendo conversaciones m√°s largas sin exceder la ventana de contexto del modelo. Adem√°s, los res√∫menes destilan la informaci√≥n esencial, filtrando el ruido y los detalles redundantes, lo que ayuda al agente a mantenerse enfocado en el contexto relevante y protege mejor la privacidad al poder excluir datos sensibles.

### ¬øQu√© informaci√≥n NO deber√≠as guardar en ese resumen por temas de privacidad?

Por motivos de privacidad, se debe excluir del resumen cualquier informaci√≥n de identificaci√≥n personal (PII) como n√∫meros de documentos, tarjetas de cr√©dito, direcciones exactas o datos de contacto. Tambi√©n se debe evitar almacenar informaci√≥n sensible como contrase√±as, datos m√©dicos o financieros detallados. Es crucial sanitizar estos datos para mantener la esencia de la conversaci√≥n sin comprometer la seguridad del usuario.

### ¬øReconoc√©s cu√°ndo el agente est√° llamando rag_search vs get_order_status?

S√≠, se puede reconocer f√°cilmente observando el contexto de la respuesta y los registros de ejecuci√≥n. Si el agente proporciona informaci√≥n detallada sobre ajedrez o la federaci√≥n, es evidente que utiliz√≥ `rag_search`. Por otro lado, si responde sobre el estado espec√≠fico de un pedido, ha invocado `get_order_status`. Adem√°s, las herramientas de trazabilidad y la propia interfaz de usuario suelen indicar expl√≠citamente qu√© herramienta se ha ejecutado en cada paso.

### ¬øQu√© tipo de prompts le dar√≠as al modelo para que use tools "con criterio"?

Para que el modelo utilice las herramientas con criterio, le proporcionar√≠a un prompt de sistema con pol√≠ticas claras y ejemplos "few-shot". Definir√≠a reglas expl√≠citas sobre cu√°ndo usar cada herramienta (por ejemplo, "usa RAG solo para preguntas de ajedrez" o "usa la herramienta de pedidos solo con IDs v√°lidos") y cu√°ndo confiar en su conocimiento general. Tambi√©n incluir√≠a instrucciones para que sea honesto si no tiene informaci√≥n y para que pida aclaraciones si la solicitud del usuario es ambigua, fomentando un razonamiento previo antes de actuar.

### ¬øC√≥mo decidir√≠as cada cu√°nto actualizar el summary?

La decisi√≥n de actualizar el resumen depender√≠a de un equilibrio entre mantener el contexto fresco y minimizar el c√≥mputo. Una estrategia efectiva ser√≠a actualizarlo despu√©s de eventos significativos, como el uso de herramientas que aportan nueva informaci√≥n externa, o tras un n√∫mero fijo de intercambios de mensajes para evitar que el historial reciente crezca demasiado. Un enfoque h√≠brido que combine estos criterios con la detecci√≥n de cambios de tema ser√≠a ideal para entornos de producci√≥n.

### ¬øQu√© tipo de info deber√≠as excluir del summary?

Del resumen se debe excluir toda informaci√≥n transitoria o sin valor futuro, como saludos, confirmaciones simples, errores de tipeo corregidos o charlas triviales. Tambi√©n se debe omitir informaci√≥n que ya ha sido resuelta y no requiere seguimiento, as√≠ como metadatos t√©cnicos irrelevantes para el contexto de la conversaci√≥n. El objetivo es conservar solo los puntos clave, decisiones y datos que son necesarios para entender y continuar el di√°logo de manera coherente.

## Conclusi√≥n

Esta pr√°ctica confirma la capacidad de LangGraph para crear agentes aut√≥nomos que integran razonamiento, herramientas externas como RAG y gesti√≥n de memoria conversacional. Aprendimos que definir un estado tipado es crucial para la consistencia del flujo, que utilizar RAG como una herramienta flexible permite evitar b√∫squedas innecesarias, y que la memoria basada en res√∫menes optimiza costos y latencia. Adem√°s, la experiencia destac√≥ la importancia de la observabilidad para depurar grafos complejos y la necesidad de documentar claramente las herramientas, ya que sus descripciones act√∫an como prompts impl√≠citos para el modelo.
En definitiva, LangGraph nos permite transformar simples generadores de texto en agentes capaces de razonar y actuar de manera aut√≥noma.

---

## üìö Referencias

### Documentaci√≥n LangGraph

- [LangGraph Conceptual Guide](https://langchain-ai.github.io/langgraph/concepts/) ‚Äî arquitectura de grafos, estado, nodos y edges
- [StateGraph API](https://langchain-ai.github.io/langgraph/reference/graphs/#langgraph.graph.StateGraph) ‚Äî construcci√≥n de grafos con estado tipado
- [Prebuilt Components (ToolNode)](https://langchain-ai.github.io/langgraph/reference/prebuilt/) ‚Äî nodos preconfigurados para tools
- [LangGraph Tutorials](https://langchain-ai.github.io/langgraph/tutorials/) ‚Äî tutoriales de agentes, RAG, multi-agent
- [Checkpointing & Persistence](https://langchain-ai.github.io/langgraph/how-tos/persistence/) ‚Äî guardar y recuperar estado de conversaciones

### Documentaci√≥n LangChain

- [Tools Conceptual Guide](https://python.langchain.com/docs/concepts/tools/) ‚Äî c√≥mo crear tools con `@tool` decorator
- [LangSmith Tracing](https://docs.smith.langchain.com/) ‚Äî observabilidad y debugging de grafos
- [FAISS VectorStore](https://python.langchain.com/docs/integrations/vectorstores/faiss/) ‚Äî vector store local para RAG

### Recursos Adicionales

- [Gradio Documentation](https://www.gradio.app/docs) ‚Äî creaci√≥n de interfaces web interactivas
- [Building Agents with LangGraph (Blog)](https://blog.langchain.dev/langgraph-multi-agent-workflows/) ‚Äî patrones de multi-agent workflows
