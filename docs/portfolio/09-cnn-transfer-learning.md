# TA9 - CNNs y Transfer Learning: De Redes Convolucionales a Modelos Preentrenados

## Resumen de la Tarea

Esta tarea explor칩 el mundo de las **Redes Neuronales Convolucionales (CNNs)** y el **Transfer Learning**, dos pilares fundamentales del Deep Learning moderno para visi칩n por computadora. El objetivo fue comprender c칩mo las CNNs procesan im치genes de manera m치s efectiva que las redes densas (MLPs), y c칩mo aprovechar modelos preentrenados para mejorar el rendimiento con menos datos y tiempo de entrenamiento.

### Metodolog칤a

1. **Preparaci칩n del dataset**: CIFAR-10 con normalizaci칩n y one-hot encoding
2. **CNN desde cero**: Implementaci칩n de una arquitectura convolucional simple
3. **Transfer Learning**: Uso de MobileNetV2 preentrenado en ImageNet
4. **Fine-tuning**: Descongelamiento de capas para ajuste fino
5. **Comparaci칩n de arquitecturas**: Evaluaci칩n de 9 modelos preentrenados diferentes
6. **An치lisis de overfitting**: Comparaci칩n de gaps entre train y validation accuracy

## Implementaci칩n y Resultados

### Dataset: CIFAR-10

**Caracter칤sticas del dataset**: CIFAR-10 contiene 50,000 im치genes de entrenamiento y 10,000 de test, todas con dimensiones de 32칑32 p칤xeles en RGB. El dataset incluye 10 clases balanceadas: airplane, automobile, bird, cat, deer, dog, frog, horse, ship y truck.

### Parte 1: CNN Simple desde Cero

#### Arquitectura

**Caracter칤sticas de la arquitectura**: La primera capa convolucional utiliza 32 filtros de 3칑3 para detectar patrones b치sicos como bordes y colores, seguida de MaxPooling que reduce las dimensiones de 32칑32 a 16칑16. La segunda capa convolucional con 64 filtros de 3칑3 detecta patrones m치s complejos, y otro MaxPooling reduce las dimensiones de 16칑16 a 8칑8. La capa Flatten convierte la matriz 8칑8칑64 en un vector de 4,096 elementos, que alimenta una capa Dense de clasificaci칩n con 512 neuronas. El modelo resultante tiene 2,122,186 par치metros totales entrenables.

#### Resultados CNN Simple

| M칠trica | Valor |
|---------|-------|
| **Training Accuracy** | 86.8% |
| **Validation Accuracy** | 69.4% |
| **Test Accuracy** | 69.37% |
| **Overfitting Gap** | 17.4% |
| **Par치metros** | 2,122,186 |
| **칄pocas entrenadas** | 9/10 (EarlyStopping) |

La CNN alcanz칩 una mejora significativa con 69.37% de accuracy frente al 56.2% del mejor MLP del TA8, aunque presenta overfitting moderado con un gap de 17.4% entre train y validation. El modelo mostr칩 convergencia r치pida alcanzando buen rendimiento en solo 9 칠pocas. Por clase, el mejor desempe침o fue en ship (88%), automobile (87%) y frog (84%), mientras que la clase m치s dif칤cil fue cat (47%).

![Comparaci칩n de precisi칩n entre CNN Simple y Transfer Learning](09-imagenes/cnn-vs-transfer-learning.png)

*Gr치ficas comparativas mostrando la evoluci칩n de la precisi칩n en validaci칩n durante el entrenamiento (izquierda) y la precisi칩n final de ambos modelos (derecha). La CNN Simple converge m치s r치pido y alcanza mejor rendimiento que Transfer Learning sin fine-tuning.*

### Parte 2: Transfer Learning con MobileNetV2

#### 쯈u칠 es Transfer Learning?

Transfer Learning utiliza un modelo preentrenado en un dataset grande (como ImageNet con 1.4M im치genes) y lo adapta a nuestro problema espec칤fico. Las ventajas principales son entrenamiento m치s r치pido, mejor rendimiento con menos datos, aprovechamiento del conocimiento previo de patrones visuales, y menos par치metros a entrenar.

#### Arquitectura Transfer Learning

**Caracter칤sticas**:
- **Base model**: MobileNetV2 preentrenado en ImageNet
- **Capas congeladas**: 2,257,984 par치metros (no se entrenan)
- **Capas entrenables**: 12,810 par치metros (solo clasificador final)
- **Par치metros totales**: 2,270,794

#### Resultados Transfer Learning (Inicial)

| M칠trica | Valor |
|---------|-------|
| **Training Accuracy** | 91.8% |
| **Validation Accuracy** | 51.1% |
| **Test Accuracy** | 51.09% |
| **Overfitting Gap** | 40.7% |
| **Par치metros entrenables** | 12,810 |

**Observaciones**: El modelo de Transfer Learning obtuvo un rendimiento significativamente peor que la CNN simple (51.09% vs 69.37%) y present칩 un overfitting severo con un gap de 40.7%, el doble que el modelo base. El problema principal es que al mantener el modelo base congelado, este no logra adaptarse correctamente a las caracter칤sticas espec칤ficas de CIFAR-10.

### Parte 3: Fine-tuning

El fine-tuning consiste en **descongelar las 칰ltimas capas** del modelo preentrenado y entrenarlas con un learning rate muy bajo para que se adapten a nuestro dataset espec칤fico.

### Parte 4: Comparaci칩n de Arquitecturas Preentrenadas

Se evaluaron **9 modelos diferentes** de Keras Applications para identificar cu치l funciona mejor en CIFAR-10:

| Ranking | Modelo | Test Acc | Par치metros | Eficiencia* |
|---------|--------|----------|------------|-------------|
| 游볞 | **ResNet50** | 27.02% | 24.1M | 0.011 |
| 游볟 | **ResNet152** | 26.31% | 58.9M | 0.004 |
| 游볠 | **ResNet101** | 26.10% | 43.2M | 0.006 |
| 4 | VGG16 | ~25% | 14.7M | 0.017 |
| 5 | VGG19 | ~24% | 20.0M | 0.012 |
| 6 | EfficientNetB0 | ~23% | 4.0M | 0.058 |
| 7 | EfficientNetB3 | ~22% | 10.7M | 0.021 |
| 8 | MobileNetV2 | ~21% | 2.3M | 0.091 |
| 9 | MobileNetV3Large | ~20% | 2.9M | 0.069 |

*Eficiencia = Test Accuracy / Millones de par치metros

![Comparaci칩n de arquitecturas preentrenadas](09-imagenes/model-comparison.png)

*Comparaci칩n visual de 9 arquitecturas preentrenadas. Izquierda: Test Accuracy por modelo, donde VGG16 y VGG19 lideran con ~60% de precisi칩n. Derecha: Tama침o del modelo en millones de par치metros, mostrando que ResNet152 es el m치s grande (60M) mientras que MobileNet son los m치s eficientes (~2-3M par치metros).*

**Observaciones importantes**: Todos los modelos de transfer learning obtuvieron accuracy muy bajo (20-27%), incluso peor que el baseline MLP (47.4%). Esto se debe a pocas 칠pocas de entrenamiento (solo 5 para comparaci칩n r치pida), capas base completamente congeladas sin fine-tuning, mismatch de dominios entre ImageNet (224칑224) e im치genes de CIFAR-10 (32칑32), y configuraci칩n sub칩ptima del learning rate y arquitectura del clasificador.

### An치lisis Comparativo: CNN vs Transfer Learning

![Comparaci칩n de precisi칩n entre CNN Simple y Transfer Learning](09-imagenes/cnn-vs-transfer-learning.png)

*La CNN Simple (azul) muestra una convergencia m치s estable y alcanza 69.4% de precisi칩n, mientras que Transfer Learning (rojo) sin fine-tuning solo alcanza 51.1%. La diferencia de 18.3% demuestra la importancia de adaptar correctamente los modelos preentrenados al dominio espec칤fico.*

## Reflexi칩n y An치lisis

### 1. 쯇or qu칠 las CNNs superan a las MLPs en im치genes?

Las CNNs preservan la estructura espacial manteniendo la relaci칩n entre p칤xeles vecinos mientras que las MLPs aplanan la imagen perdiendo esta informaci칩n, tienen invarianza traslacional donde un filtro detecta el mismo patr칩n independientemente de su posici칩n (una MLP necesitar칤a aprender el mismo patr칩n en cada ubicaci칩n), comparten par치metros aplicando los filtros a toda la imagen reduciendo dr치sticamente el n칰mero de par치metros comparado con capas densas, y aprenden autom치ticamente una jerarqu칤a de caracter칤sticas donde la primera capa detecta bordes y colores b치sicos, la segunda capa texturas y patrones simples, y las capas superiores partes de objetos y objetos completos. Por ejemplo, para detectar un "ojo de gato", una MLP necesita aprender "ojo en posici칩n (10,15)", "ojo en posici칩n (10,16)", etc. requiriendo miles de conexiones, mientras que una CNN aprende un filtro "detector de ojos" que funciona en cualquier posici칩n con solo 9 par치metros (filtro 3칑3).

### 2. El Problema del Transfer Learning en CIFAR-10

Sorprendentemente, el transfer learning mostr칩 resultados peores que una CNN simple (51.09% vs 69.37%). Este resultado aparentemente contradictorio se explica por errores en la implementaci칩n:

#### Causas del Bajo Rendimiento

**A. Preprocesamiento Incorrecto** 丘멆잺

El error m치s grave: se normalizaron todas las im치genes a [0,1] mediante `x/255.0`, pero MobileNetV2 espera im치genes en rango [-1, 1]

Cuando el modelo recibe datos en un rango diferente al que vio durante su entrenamiento en ImageNet, los features extra칤dos por las capas convolucionales son incorrectos, anulando el beneficio del transfer learning.
**B. Mismatch de Resoluci칩n**

- ImageNet: im치genes de **224칑224** p칤xeles
- CIFAR-10: im치genes de **32칑32** p칤xeles (7칑 m치s peque침as por lado)

Los filtros convolucionales entrenados en im치genes grandes no se adaptan bien a im치genes tan peque침as. Por ejemplo, un filtro 7칑7 en una imagen 224칑224 captura detalles locales, pero en 32칑32 cubre gran parte de la imagen completa.
**C. Configuraci칩n Sub칩ptima**

- Aumentar el numero de epocas a 20-30
- Se podria usar alguna tecnica de data augmentation

### 4. Comparaci칩n de Modelos Preentrenados

De los 9 modelos evaluados, observamos distintos patrones:

**Modelos grandes (ResNet50, ResNet101, ResNet152)**: Estos modelos tienen mayor capacidad de representaci칩n pero son m치s lentos de entrenar y presentan mayor riesgo de overfitting con pocos datos. El mejor de esta categor칤a fue ResNet50 con 27.02% de accuracy.

**Modelos eficientes (MobileNet, EfficientNet)**: Son muy r치pidos y ligeros, dise침ados espec칤ficamente para dispositivos m칩viles, aunque tienen menor capacidad de representaci칩n comparados con modelos m치s grandes. MobileNetV2 destac칩 con la mejor eficiencia de 0.091 acc/M params.

**Modelos cl치sicos (VGG16, VGG19)**: Tienen una arquitectura simple y comprensible pero muchos par치metros haci칠ndolos poco eficientes, y est치n obsoletos comparados con arquitecturas modernas como ResNet o EfficientNet.

![Comparaci칩n de arquitecturas preentrenadas](09-imagenes/model-comparison.png)

*Las gr치ficas muestran que los modelos VGG obtienen el mejor rendimiento (60%) con tama침o moderado, los MobileNet son muy ligeros pero menos precisos (20-30%), y el ResNet152 siendo el m치s grande no logra el mejor resultado, demostrando que m치s par치metros no siempre es mejor.*

### 5. Lecciones Aprendidas

**Sobre CNNs**: Las CNNs son fundamentalmente superiores a las MLPs para visi칩n por computadora, donde incluso una CNN simple supera a MLPs complejas con regularizaci칩n avanzada. La estructura convolucional captura naturalmente patrones espaciales preservando la informaci칩n de vecindad entre p칤xeles, lo que las hace la arquitectura ideal para procesamiento de im치genes.

**Sobre Transfer Learning**: Transfer learning no es una soluci칩n m치gica y requiere configuraci칩n cuidadosa. El mismatch de dominio puede hacer que funcione peor que entrenar desde cero, como observamos en CIFAR-10 donde la diferencia de resoluci칩n con ImageNet afect칩 significativamente los resultados. Cuando funciona bien ahorra tiempo y mejora resultados significativamente, pero el fine-tuning es casi siempre necesario para obtener buenos resultados.

**Sobre el proceso de experimentaci칩n**: Es fundamental siempre comparar con un baseline simple como una CNN desde cero para evaluar si el transfer learning realmente aporta valor. Debemos monitorear el overfitting gap y no solo el test accuracy, considerar trade-offs entre accuracy, velocidad y n칰mero de par치metros, y probar m칰ltiples arquitecturas antes de tomar una decisi칩n final sobre qu칠 modelo deployar en producci칩n.

## Conclusiones

La superioridad de las CNNs sobre las MLPs qued칩 claramente demostrada con una CNN simple alcanzando casi 70% de test accuracy, una mejora importante lograda con una arquitectura simple de solo 2 bloques convolucionales. Esta tarea demostr칩 que **la arquitectura importa tanto como los hiperpar치metros**; en la TA8 optimizamos exhaustivamente MLPs alcanzando solo 56.2%, mientras que una CNN simple super칩 ese resultado en la primera iteraci칩n.

El transfer learning no funcion칩 bien "out of the box" debido al mismatch entre ImageNet y CIFAR-10, pero con configuraciones adecuadas (fine-tuning, data augmentation, clasificador m치s complejo) se podr칤a igualar o superar a la CNN simple. La recomendaci칩n es usar CNN desde cero cuando se tiene un dataset suficientemente grande y dominio espec칤fico, mientras que transfer learning es preferible con pocos datos, dominio similar a ImageNet o tiempo limitado. Esto ilustra un principio fundamental del deep learning: **usar la arquitectura correcta para el problema correcto es m치s importante que optimizar una arquitectura incorrecta**.

---

### Recursos adicionales

- [CS231n: Convolutional Neural Networks](http://cs231n.stanford.edu/)
- [Transfer Learning Guide - Keras](https://keras.io/guides/transfer_learning/)
- [CIFAR-10 Benchmark](https://paperswithcode.com/sota/image-classification-on-cifar-10)
