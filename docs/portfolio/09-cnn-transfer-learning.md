# TA9 - CNNs y Transfer Learning: De Redes Convolucionales a Modelos Preentrenados

## Resumen de la Tarea

Esta tarea explor√≥ el mundo de las **Redes Neuronales Convolucionales (CNNs)** y el **Transfer Learning**, dos pilares fundamentales del Deep Learning moderno para visi√≥n por computadora. El objetivo fue comprender c√≥mo las CNNs procesan im√°genes de manera m√°s efectiva que las redes densas (MLPs), y c√≥mo aprovechar modelos preentrenados para mejorar el rendimiento con menos datos y tiempo de entrenamiento.

### Metodolog√≠a

1. **Preparaci√≥n del dataset**: CIFAR-10 con normalizaci√≥n y one-hot encoding
2. **CNN desde cero**: Implementaci√≥n de una arquitectura convolucional simple
3. **Transfer Learning**: Uso de MobileNetV2 preentrenado en ImageNet
4. **preprocesamiento**: Aplicaci√≥n de preprocesamiento espec√≠fico por modelo
5. **Fine-tuning**: Descongelamiento de √∫ltimas 10 capas (745,290 par√°metros entrenables)
6. **Extra:**: Evaluaci√≥n de 9 modelos

## Implementaci√≥n y Resultados

### Dataset: CIFAR-10

**Caracter√≠sticas del dataset**: CIFAR-10 contiene 50,000 im√°genes de entrenamiento y 10,000 de test, todas con dimensiones de 32√ó32 p√≠xeles en RGB. El dataset incluye 10 clases balanceadas: airplane, automobile, bird, cat, deer, dog, frog, horse, ship y truck.

### CNN Simple desde Cero

#### Arquitectura

**Caracter√≠sticas de la arquitectura**: La primera capa convolucional utiliza 32 filtros de 3√ó3 para detectar patrones b√°sicos como bordes y colores, seguida de MaxPooling que reduce las dimensiones de 32√ó32 a 16√ó16. La segunda capa convolucional con 64 filtros de 3√ó3 detecta patrones m√°s complejos, y otro MaxPooling reduce las dimensiones de 16√ó16 a 8√ó8. La capa Flatten convierte la matriz 8√ó8√ó64 en un vector de 4,096 elementos, que alimenta una capa Dense de clasificaci√≥n con 512 neuronas. El modelo resultante tiene 2,122,186 par√°metros totales entrenables.

#### Resultados CNN Simple

| M√©trica | Valor |
|---------|-------|
| **Training Accuracy** | 86.8% |
| **Validation Accuracy** | 69.4% |
| **Test Accuracy** | 69.37% |
| **Overfitting Gap** | 17.4% |
| **Par√°metros** | 2,122,186 |
| **√âpocas entrenadas** | 9/10 (EarlyStopping) |

La CNN alcanz√≥ una mejora significativa con 69.37% de accuracy frente al 56.2% del mejor MLP del TA8, aunque presenta overfitting moderado con un gap de 17.4% entre train y validation. El modelo mostr√≥ convergencia r√°pida alcanzando buen rendimiento en solo 9 √©pocas. Por clase, el mejor desempe√±o fue en ship (88%), automobile (87%) y frog (84%), mientras que la clase m√°s dif√≠cil fue cat (47%).

![Comparaci√≥n de precisi√≥n entre CNN Simple y Transfer Learning](09-imagenes/cnn-vs-transfer-learning.png)

*Gr√°ficas comparativas mostrando la evoluci√≥n de la precisi√≥n en validaci√≥n durante el entrenamiento (izquierda) y la precisi√≥n final de ambos modelos (derecha). La CNN Simple converge m√°s r√°pido y alcanza mejor rendimiento que Transfer Learning sin fine-tuning.*

### Transfer Learning con MobileNetV2

#### ¬øQu√© es Transfer Learning?

Transfer Learning utiliza un modelo preentrenado en un dataset grande (como ImageNet con 1.4M im√°genes) y lo adapta a nuestro problema espec√≠fico. Las ventajas principales son entrenamiento m√°s r√°pido, mejor rendimiento con menos datos, aprovechamiento del conocimiento previo de patrones visuales, y menos par√°metros a entrenar.

#### Arquitectura Transfer Learning

**Caracter√≠sticas**:

- **Base model**: MobileNetV2 preentrenado en ImageNet
- **Capas congeladas**: 2,257,984 par√°metros (no se entrenan)
- **Capas entrenables**: 12,810 par√°metros (solo clasificador final)
- **Par√°metros totales**: 2,270,794

#### Preprocesamiento Correcto

**Descubrimiento importante**: El preprocesamiento es CR√çTICO en transfer learning, ya que cada arquitectura preentrenada espera que las im√°genes est√©n preprocesadas de forma espec√≠fica (por ejemplo, **MobileNetV2** espera valores en rango [-1, 1]). Usar una normalizaci√≥n simple [0, 1] para todos los modelos fue un error que caus√≥ resultados muy bajos, pero al aplicar el preprocesamiento correcto, los resultados mejoraron.

#### Resultados Transfer Learning

| M√©trica | Valor |
|---------|-------|
| **Training Accuracy** | 99.9% |
| **Validation Accuracy** | 55.5% |
| **Test Accuracy** | 55.5% |
| **Overfitting Gap** | 44.5% |
| **Par√°metros entrenables** | 12,810 |

### Fine-tuning

El fine-tuning consiste en **descongelar las √∫ltimas capas** del modelo preentrenado y entrenarlas con un learning rate muy bajo para que se adapten a nuestro dataset espec√≠fico.

**Configuraci√≥n aplicada**:

- **Capas descongeladas**: √öltimas 10 capas
- **Learning rate**: 0.0001
- **√âpocas**: 20

Con fine-tuning, el modelo alcanza mayor capacidad de adaptaci√≥n al dataset espec√≠fico, aunque sigue presentando overfitting considerable.

### (Extra): Comparaci√≥n de Arquitecturas Preentrenadas

Se evaluaron **9 modelos diferentes** de Keras Applications con el preprocesamiento espec√≠fico de cada uno:

| Ranking | Modelo | Test Acc | Par√°metros | Eficiencia* |
|---------|--------|----------|------------|-------------|
| ü•á | **ResNet50** | 66.01% | 24.1M | 0.027 |
| ü•à | **ResNet101** | 65.41% | 43.2M | 0.015 |
| ü•â | **ResNet152** | 64.77% | 58.9M | 0.011 |
| 4 | VGG16 | 63.71% | 14.8M | 0.043 |
| 5 | VGG19 | 62.03% | 20.2M | 0.031 |
| 6 | EfficientNetB0 | 57.13% | 4.4M | 0.130 |
| 7 | EfficientNetB3 | 49.19% | 11.2M | 0.044 |
| 8 | MobileNetV3Large | 46.78% | 3.2M | 0.146 |
| 9 | MobileNetV2 | 29.94% | 2.6M | 0.115 |

*Eficiencia = Test Accuracy / Millones de par√°metros

![Comparaci√≥n de arquitecturas preentrenadas](09-imagenes/model-comparison-sin-pre.png)

![Comparaci√≥n de arquitecturas preentrenadas](09-imagenes/model-comparison.png)

*Comparaci√≥n visual de 9 arquitecturas preentrenadas CON preprocesamiento correcto. La mejora es tremenda: ResNet50 pasa de ~27% a 66%, casi triplicando su accuracy. Esto demuestra el impacto CR√çTICO del preprocesamiento en transfer learning.*

**Impacto del Preprocesamiento**:

| Modelo | Antes | Despu√©s (correcto) | Mejora |
|--------|------------------------|-------------------|--------|
| ResNet50 | 27.02% | **66.01%** | +144% |
| VGG16 | ~25% | **63.71%** | +155% |
| EfficientNetB0 | ~23% | **57.13%** | +148% |

El preprocesamiento caus√≥ una mejora considerable en accuracy, demostrando que es absolutamente esencial aplicar la funci√≥n de preprocesamiento espec√≠fica de cada arquitectura.

Aunque todos los modelos mejoraron, ninguno supera a la CNN simple (69.76%).
Esto puede mejorarse si:
Aumentams las √©pocas de entrenamiento
O mejoramos el tama√±o de las imagenes ya que ImageNet espera imagenenes de 224√ó224 en cambio las de CIFAR-10 son de 32√ó32

### An√°lisis Comparativo: CNN vs Transfer Learning

![Comparaci√≥n de precisi√≥n entre CNN Simple y Transfer Learning](09-imagenes/cnn-vs-transfer-learning.png)

*La CNN Simple (azul) muestra una convergencia m√°s estable y alcanza 69.76% de precisi√≥n, mientras que Transfer Learning (rojo) con fine-tuning alcanza 55.5%. Aunque Transfer Learning mejor√≥ significativamente con preprocesamiento y fine-tuning, la CNN simple mantiene una ventaja del 14.2%. El overfitting es m√°s severo en Transfer Learning (44.5% vs 14.2% de gap).*

## Reflexi√≥n y An√°lisis

### 1. ¬øPor qu√© las CNNs superan a las MLPs en im√°genes?

Las CNNs preservan la estructura espacial manteniendo la relaci√≥n entre p√≠xeles vecinos mientras que las MLPs aplanan la imagen perdiendo esta informaci√≥n, tienen invarianza traslacional donde un filtro detecta el mismo patr√≥n independientemente de su posici√≥n (una MLP necesitar√≠a aprender el mismo patr√≥n en cada ubicaci√≥n), comparten par√°metros aplicando los filtros a toda la imagen reduciendo dr√°sticamente el n√∫mero de par√°metros comparado con capas densas, y aprenden autom√°ticamente una jerarqu√≠a de caracter√≠sticas donde la primera capa detecta bordes y colores b√°sicos, la segunda capa texturas y patrones simples, y las capas superiores partes de objetos y objetos completos. Por ejemplo, para detectar un "ojo de gato", una MLP necesita aprender "ojo en posici√≥n (10,15)", "ojo en posici√≥n (10,16)", etc. requiriendo miles de conexiones, mientras que una CNN aprende un filtro "detector de ojos" que funciona en cualquier posici√≥n con solo 9 par√°metros (filtro 3√ó3).

### 2. Preprocesamiento

Inicialmente, se normalizaron todas las im√°genes a [0,1] mediante `x/255.0`, ignorando que cada arquitectura espera un preprocesamiento espec√≠fico (por ejemplo, MobileNetV2 espera [-1, 1] y ResNet espera centrado de media). Este error result√≥ en accuracies muy bajos (~25% para ResNet50 y VGG16, y ~21% para MobileNetV2).

Sin embargo, al corregir el preprocesamiento utilizando las funciones espec√≠ficas de cada modelo, los resultados mejoraron mucho, alcanzando un 66% para ResNet50 y un 64% para VGG16, demostrando que los features extra√≠dos por las capas convolucionales preentrenadas son ineficaces si los datos de entrada no se encuentran en el rango y distribuci√≥n estad√≠stica con los que fue entrenado el modelo original.

### 3. Comparaci√≥n de Modelos Preentrenados

![Comparaci√≥n de arquitecturas preentrenadas](09-imagenes/model-comparison.png)

*Con preprocesamiento correcto: ResNet50 lidera con 66%, seguido de ResNet101 y ResNet152. Los modelos VGG muestran buen rendimiento considerando su simplicidad. EfficientNetB0 destaca por su eficiencia (130 acc/M params).*

### 4. Lecciones Aprendidas

**Sobre CNNs**: Las CNNs son fundamentalmente superiores a las MLPs para visi√≥n por computadora, donde incluso una CNN simple supera a MLPs complejas con regularizaci√≥n avanzada. La estructura convolucional captura naturalmente patrones espaciales preservando la informaci√≥n de vecindad entre p√≠xeles, lo que las hace la arquitectura ideal para procesamiento de im√°genes.

**Sobre Transfer Learning y el Preprocesamiento**:

el preprocesamiento espec√≠fico del modelo es M√ÅS IMPORTANTE que la arquitectura misma.

**Transfer learning no es "plug and play"**:

- Cada arquitectura tiene su funci√≥n de preprocesamiento espec√≠fica
- MobileNetV2: `mobilenet_v2.preprocess_input()` ‚Üí [-1, 1]
- ResNet/VGG: `resnet.preprocess_input()` ‚Üí [-123.68, 151.06]
- EfficientNet: `efficientnet.preprocess_input()` ‚Üí [0, 255]

**Limitaciones en CIFAR-10**:
  
- Incluso con preprocesamiento correcto y fine-tuning, Transfer Learning no super√≥ a CNN simple
- Diferencia de resoluci√≥n (ImageNet 224√ó224 vs CIFAR-10 32√ó32) sigue siendo limitante

## Conclusiones

La superioridad de las CNNs sobre las MLPs qued√≥ claramente demostrada con una CNN simple alcanzando 69.76% de test accuracy, una mejora sustancial frente al 56.2% del mejor MLP del TA8. Esta tarea demostr√≥ que **la arquitectura importa tanto como los hiperpar√°metros**: una CNN simple super√≥ MLPs exhaustivamente optimizadas en la primera iteraci√≥n.

Esta tarea ilustra un principio fundamental: **los detalles de implementaci√≥n (como preprocesamiento) pueden tener un impacto mayor que la elecci√≥n de la arquitectura**.

---

### Recursos adicionales

- [CS231n: Convolutional Neural Networks](http://cs231n.stanford.edu/)
- [Transfer Learning Guide - Keras](https://keras.io/guides/transfer_learning/)
- [CIFAR-10 Benchmark](https://paperswithcode.com/sota/image-classification-on-cifar-10)
