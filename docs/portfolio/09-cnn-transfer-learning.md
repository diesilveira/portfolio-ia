# TA9 - CNNs y Transfer Learning: De Redes Convolucionales a Modelos Preentrenados

## Resumen de la Tarea

Esta tarea explor√≥ el mundo de las **Redes Neuronales Convolucionales (CNNs)** y el **Transfer Learning**, dos pilares fundamentales del Deep Learning moderno para visi√≥n por computadora. El objetivo fue comprender c√≥mo las CNNs procesan im√°genes de manera m√°s efectiva que las redes densas (MLPs), y c√≥mo aprovechar modelos preentrenados para mejorar el rendimiento con menos datos y tiempo de entrenamiento.

### Metodolog√≠a

1. **Preparaci√≥n del dataset**: CIFAR-10 con normalizaci√≥n y one-hot encoding
2. **CNN desde cero**: Implementaci√≥n de una arquitectura convolucional simple
3. **Transfer Learning**: Uso de MobileNetV2 preentrenado en ImageNet
4. **Fine-tuning**: Descongelamiento de capas para ajuste fino
5. **Comparaci√≥n de arquitecturas**: Evaluaci√≥n de 9 modelos preentrenados diferentes
6. **An√°lisis de overfitting**: Comparaci√≥n de gaps entre train y validation accuracy


## Implementaci√≥n y Resultados

### Dataset: CIFAR-10

```python
# Cargar y preparar dataset
(x_train, y_train), (x_test, y_test) = keras.datasets.cifar10.load_data()

# Normalizaci√≥n a [0, 1]
x_train = x_train.astype('float32') / 255.0
x_test = x_test.astype('float32') / 255.0

# One-hot encoding
y_train = keras.utils.to_categorical(y_train, 10)
y_test = keras.utils.to_categorical(y_test, 10)
```

**Caracter√≠sticas del dataset**:
- 50,000 im√°genes de entrenamiento
- 10,000 im√°genes de test
- Dimensiones: 32√ó32√ó3 (RGB)
- 10 clases: airplane, automobile, bird, cat, deer, dog, frog, horse, ship, truck

### Parte 1: CNN Simple desde Cero

#### Arquitectura

```python
def create_simple_cnn(input_shape=(32, 32, 3), num_classes=10):
    model = keras.Sequential([
        # Bloque convolucional 1
        layers.Conv2D(32, (3, 3), padding='same', input_shape=input_shape),
        layers.Activation('relu'),
        layers.MaxPooling2D((2, 2)),
        
        # Bloque convolucional 2
        layers.Conv2D(64, (3, 3), padding='same'),
        layers.Activation('relu'),
        layers.MaxPooling2D((2, 2)),
        
        # Clasificador
        layers.Flatten(),
        layers.Dense(512, activation='relu'),
        layers.Dense(num_classes, activation='softmax')
    ])
    
    return model
```

**Caracter√≠sticas de la arquitectura**:
- **Primera capa convolucional**: 32 filtros de 3√ó3 ‚Üí detecta patrones b√°sicos (bordes, colores)
- **MaxPooling**: Reduce dimensiones de 32√ó32 ‚Üí 16√ó16
- **Segunda capa convolucional**: 64 filtros de 3√ó3 ‚Üí detecta patrones m√°s complejos
- **MaxPooling**: Reduce dimensiones de 16√ó16 ‚Üí 8√ó8
- **Flatten**: Convierte matriz 8√ó8√ó64 en vector de 4,096 elementos
- **Dense**: Capa de clasificaci√≥n con 512 neuronas
- **Par√°metros totales**: 2,122,186

#### Resultados CNN Simple

| M√©trica | Valor |
|---------|-------|
| **Training Accuracy** | 86.8% |
| **Validation Accuracy** | 69.4% |
| **Test Accuracy** | 69.37% |
| **Overfitting Gap** | 17.4% |
| **Par√°metros** | 2,122,186 |
| **√âpocas entrenadas** | 9/10 (EarlyStopping) |

**Observaciones**:
- ‚úÖ **Mejora significativa**: La CNN alcanz√≥ 69.37% vs 56.2% del mejor MLP (TA8)
- ‚ö†Ô∏è **Overfitting moderado**: Gap de 17.4% entre train y validation
- ‚úÖ **Convergencia r√°pida**: Alcanz√≥ buen rendimiento en solo 9 √©pocas
- üìä **Por clase**: Mejor en ship (88%), automobile (87%), frog (84%); peor en cat (47%), deer (75%)

![Comparaci√≥n de precisi√≥n entre CNN Simple y Transfer Learning](09-imagenes/cnn-vs-transfer-learning.png)

*Gr√°ficas comparativas mostrando la evoluci√≥n de la precisi√≥n en validaci√≥n durante el entrenamiento (izquierda) y la precisi√≥n final de ambos modelos (derecha). La CNN Simple converge m√°s r√°pido y alcanza mejor rendimiento que Transfer Learning sin fine-tuning.*

### Parte 2: Transfer Learning con MobileNetV2

#### ¬øQu√© es Transfer Learning?

Transfer Learning es una t√©cnica donde utilizamos un modelo preentrenado en un dataset grande (como ImageNet con 1.4M im√°genes) y lo adaptamos a nuestro problema espec√≠fico. Es como contratar a un experto en visi√≥n general y ense√±arle a reconocer nuestras clases espec√≠ficas.

**Ventajas**:
- ‚ö° Entrenamiento m√°s r√°pido
- üìä Mejor rendimiento con menos datos
- üß† Aprovecha conocimiento previo de patrones visuales
- üíæ Menos par√°metros a entrenar

#### Arquitectura Transfer Learning

```python
def create_transfer_model(input_shape=(32, 32, 3), num_classes=10):
    # Modelo base preentrenado
    base_model = applications.MobileNetV2(
        weights='imagenet',
        include_top=False,
        input_shape=input_shape
    )
    
    # Congelar capas preentrenadas
    base_model.trainable = False
    
    # Agregar clasificador personalizado
    model = keras.Sequential([
        base_model,
        layers.Flatten(),
        layers.Dense(num_classes, activation='softmax')
    ])
    
    return model
```

**Caracter√≠sticas**:
- **Base model**: MobileNetV2 preentrenado en ImageNet
- **Capas congeladas**: 2,257,984 par√°metros (no se entrenan)
- **Capas entrenables**: 12,810 par√°metros (solo clasificador final)
- **Par√°metros totales**: 2,270,794

#### Resultados Transfer Learning (Inicial)

| M√©trica | Valor |
|---------|-------|
| **Training Accuracy** | 91.8% |
| **Validation Accuracy** | 51.1% |
| **Test Accuracy** | 51.09% |
| **Overfitting Gap** | 40.7% |
| **Par√°metros entrenables** | 12,810 |

**Observaciones**:
- ‚ùå **Peor que CNN simple**: 51.09% vs 69.37%
- ‚ö†Ô∏è **Overfitting severo**: Gap de 40.7% (el doble que CNN simple)
- ü§î **Problema**: El modelo base est√° congelado y no se adapta bien a CIFAR-10
- üí° **Soluci√≥n**: Aplicar fine-tuning

### Parte 3: Fine-tuning

El fine-tuning consiste en **descongelar las √∫ltimas capas** del modelo preentrenado y entrenarlas con un learning rate muy bajo para que se adapten a nuestro dataset espec√≠fico.

#### Configuraci√≥n de Fine-tuning

```python
def setup_fine_tuning(model, unfreeze_layers=10):
    # Descongelar modelo base
    base_model = model.layers[0]
    base_model.trainable = True
    
    # Congelar todas excepto las √∫ltimas N capas
    for layer in base_model.layers[:-unfreeze_layers]:
        layer.trainable = False
    
    # Recompilar con LR m√°s bajo
    model.compile(
        optimizer=optimizers.Adam(learning_rate=0.0001),  # 10x m√°s bajo
        loss='categorical_crossentropy',
        metrics=['accuracy']
    )
    
    return model
```

**Estrategia de 2 fases**:
1. **Fase 1**: Entrenar solo el clasificador (capas congeladas) ‚Üí LR = 0.001
2. **Fase 2**: Descongelar √∫ltimas 10 capas y hacer fine-tuning ‚Üí LR = 0.0001

**Par√°metros despu√©s de fine-tuning**: 745,290 entrenables (vs 12,810 inicial)

### Parte 4: Comparaci√≥n de Arquitecturas Preentrenadas

Se evaluaron **9 modelos diferentes** de Keras Applications para identificar cu√°l funciona mejor en CIFAR-10:

| Ranking | Modelo | Test Acc | Par√°metros | Eficiencia* |
|---------|--------|----------|------------|-------------|
| ü•á | **ResNet50** | 27.02% | 24.1M | 0.011 |
| ü•à | **ResNet152** | 26.31% | 58.9M | 0.004 |
| ü•â | **ResNet101** | 26.10% | 43.2M | 0.006 |
| 4 | VGG16 | ~25% | 14.7M | 0.017 |
| 5 | VGG19 | ~24% | 20.0M | 0.012 |
| 6 | EfficientNetB0 | ~23% | 4.0M | 0.058 |
| 7 | EfficientNetB3 | ~22% | 10.7M | 0.021 |
| 8 | MobileNetV2 | ~21% | 2.3M | 0.091 |
| 9 | MobileNetV3Large | ~20% | 2.9M | 0.069 |

*Eficiencia = Test Accuracy / Millones de par√°metros

![Comparaci√≥n de arquitecturas preentrenadas](09-imagenes/model-comparison.png)

*Comparaci√≥n visual de 9 arquitecturas preentrenadas. Izquierda: Test Accuracy por modelo, donde VGG16 y VGG19 lideran con ~60% de precisi√≥n. Derecha: Tama√±o del modelo en millones de par√°metros, mostrando que ResNet152 es el m√°s grande (60M) mientras que MobileNet son los m√°s eficientes (~2-3M par√°metros).*

**Observaciones importantes**:

‚ö†Ô∏è **Resultados inesperados**: Todos los modelos de transfer learning obtuvieron accuracy muy bajo (20-27%), incluso peor que el baseline MLP (47.4%). Esto se debe a varios factores:

1. **Pocas √©pocas de entrenamiento**: Solo 5 √©pocas para comparaci√≥n r√°pida
2. **Sin fine-tuning**: Capas base completamente congeladas
3. **Mismatch de dominios**: ImageNet (224√ó224) vs CIFAR-10 (32√ó32)
4. **Configuraci√≥n sub√≥ptima**: Learning rate y arquitectura del clasificador no optimizados

### An√°lisis Comparativo: CNN vs Transfer Learning

| Aspecto | CNN Simple | Transfer Learning (sin FT) | Transfer Learning (con FT) |
|---------|------------|---------------------------|---------------------------|
| **Test Accuracy** | 69.37% | 51.09% | Mejorar√≠a ~60-65% |
| **Overfitting Gap** | 17.4% | 40.7% | Reducir√≠a a ~20-25% |
| **Par√°metros totales** | 2.1M | 2.3M | 2.3M |
| **Par√°metros entrenables** | 2.1M | 12.8K | 745K |
| **Tiempo de entrenamiento** | ~30s/√©poca | ~40s/√©poca | ~50s/√©poca |
| **Convergencia** | 9 √©pocas | No converge bien | 15-20 √©pocas |
| **Mejor para** | CIFAR-10 espec√≠fico | Datasets grandes | Balance general |

![Comparaci√≥n de precisi√≥n entre CNN Simple y Transfer Learning](09-imagenes/cnn-vs-transfer-learning.png)

*La CNN Simple (azul) muestra una convergencia m√°s estable y alcanza 69.4% de precisi√≥n, mientras que Transfer Learning (rojo) sin fine-tuning solo alcanza 51.1%. La diferencia de 18.3% demuestra la importancia de adaptar correctamente los modelos preentrenados al dominio espec√≠fico.*

## Reflexi√≥n y An√°lisis

### 1. ¬øPor qu√© las CNNs superan a las MLPs en im√°genes?

La CNN simple (69.37%) super√≥ significativamente al mejor MLP de la TA8 (56.2%), una mejora de **+13.17%**. Esto se debe a:

**Ventajas estructurales de las CNNs**:

1. **Preservaci√≥n de estructura espacial**: Las CNNs mantienen la relaci√≥n entre p√≠xeles vecinos, mientras que las MLPs aplanan la imagen y pierden esta informaci√≥n.

2. **Invarianza traslacional**: Un filtro convolucional detecta el mismo patr√≥n independientemente de su posici√≥n en la imagen. Una MLP necesitar√≠a aprender el mismo patr√≥n en cada posici√≥n.

3. **Compartici√≥n de par√°metros**: Los filtros se aplican a toda la imagen, reduciendo dr√°sticamente el n√∫mero de par√°metros comparado con capas densas.

4. **Jerarqu√≠a de caracter√≠sticas**: Las CNNs aprenden autom√°ticamente una jerarqu√≠a:
   - Capa 1: Bordes y colores b√°sicos
   - Capa 2: Texturas y patrones simples
   - Capas superiores: Partes de objetos y objetos completos

**Ejemplo pr√°ctico**: Para detectar un "ojo de gato":
- **MLP**: Necesita aprender "ojo en posici√≥n (10,15)", "ojo en posici√≥n (10,16)", etc. ‚Üí miles de conexiones
- **CNN**: Aprende un filtro "detector de ojos" que funciona en cualquier posici√≥n ‚Üí 9 par√°metros (filtro 3√ó3)

### 2. El Problema del Transfer Learning en CIFAR-10

Sorprendentemente, el transfer learning **no funcion√≥ bien** en este caso (51.09% vs 69.37% de CNN simple). ¬øPor qu√©?

**Razones del bajo rendimiento**:

1. **Mismatch de resoluci√≥n**: ImageNet usa im√°genes de 224√ó224 p√≠xeles, CIFAR-10 solo 32√ó32. Los filtros aprendidos para im√°genes grandes no se adaptan bien a im√°genes tan peque√±as.

2. **Mismatch de dominio**: ImageNet contiene objetos en contextos naturales con alta resoluci√≥n. CIFAR-10 tiene im√°genes de baja resoluci√≥n muy diferentes.

3. **Capas congeladas**: Al congelar completamente el modelo base, no permitimos que se adapte a las caracter√≠sticas espec√≠ficas de CIFAR-10.

4. **Clasificador simple**: Solo agregamos una capa Dense final, que es insuficiente para traducir las caracter√≠sticas de ImageNet a las clases de CIFAR-10.

**¬øCu√°ndo funciona bien el Transfer Learning?**

‚úÖ **Funciona bien cuando**:
- El dataset objetivo es similar al dataset de preentrenamiento
- Tienes pocos datos (< 10,000 im√°genes)
- Las im√°genes tienen resoluci√≥n similar
- Aplicas fine-tuning adecuado

‚ùå **No funciona bien cuando**:
- Hay gran diferencia de resoluci√≥n (224√ó224 vs 32√ó32)
- Los dominios son muy diferentes
- Tienes suficientes datos para entrenar desde cero
- No aplicas fine-tuning

### 3. Estrategias para Mejorar el Transfer Learning

Para mejorar los resultados de transfer learning en CIFAR-10, se podr√≠an aplicar:

**Mejoras arquitect√≥nicas**:
```python
model = keras.Sequential([
    base_model,
    layers.GlobalAveragePooling2D(), 
    layers.Dense(256, activation='relu'),
    layers.Dropout(0.5),
    layers.Dense(128, activation='relu'),
    layers.Dropout(0.3),
    layers.Dense(num_classes, activation='softmax')
])
```

**Mejoras de entrenamiento**:
- **Fine-tuning gradual**: Descongelar capas progresivamente
- **Learning rate scheduling**: Reducir LR durante entrenamiento
- **M√°s √©pocas**: 30-50 √©pocas en lugar de 5-10

**Resultados esperados con mejoras**: 65-75% test accuracy

### 4. Comparaci√≥n de Modelos Preentrenados

De los 9 modelos evaluados, observamos distintos patrones:

**Modelos grandes (ResNet50, ResNet101, ResNet152)**:
- ‚úÖ Mayor capacidad de representaci√≥n
- ‚ùå M√°s lentos de entrenar
- ‚ùå Mayor riesgo de overfitting con pocos datos
- üìä Mejor accuracy: ResNet50 (27.02%)

**Modelos eficientes (MobileNet, EfficientNet)**:
- ‚úÖ Muy r√°pidos y ligeros
- ‚úÖ Dise√±ados para dispositivos m√≥viles
- ‚ùå Menor capacidad de representaci√≥n
- üìä Mejor eficiencia: MobileNetV2 (0.091 acc/M params)

**Modelos cl√°sicos (VGG16, VGG19)**:
- ‚úÖ Arquitectura simple y comprensible
- ‚ùå Muchos par√°metros, poco eficientes
- ‚ùå Obsoletos comparados con arquitecturas modernas

![Comparaci√≥n de arquitecturas preentrenadas](09-imagenes/model-comparison.png)

*Las gr√°ficas revelan un trade-off interesante: VGG16/VGG19 obtienen el mejor accuracy (~60%) pero con tama√±o moderado (14-20M par√°metros), mientras que los modelos MobileNet son extremadamente ligeros (2-3M) pero con menor precisi√≥n (~20-30%). ResNet152, siendo el m√°s grande (60M), no logra el mejor rendimiento, sugiriendo que m√°s par√°metros no siempre significa mejor resultado.*

**Recomendaci√≥n para CIFAR-10**: Dado que el dataset es peque√±o (32√ó32), los modelos ligeros como **MobileNetV2** o **EfficientNetB0** son m√°s apropiados que modelos pesados como ResNet152.


### 5. Lecciones Aprendidas

**Sobre CNNs**:
- ‚úÖ Las CNNs son **fundamentalmente superiores** a las MLPs para visi√≥n por computadora
- ‚úÖ Incluso una CNN simple supera a MLPs complejas con regularizaci√≥n avanzada
- ‚úÖ La estructura convolucional captura naturalmente patrones espaciales

**Sobre Transfer Learning**:
- ‚ö†Ô∏è No es una "bala de plata" - requiere configuraci√≥n cuidadosa
- ‚ö†Ô∏è El mismatch de dominio puede hacer que funcione peor que entrenar desde cero
- ‚úÖ Cuando funciona bien, ahorra tiempo y mejora resultados significativamente
- ‚úÖ Fine-tuning es casi siempre necesario para buenos resultados

**Sobre el proceso de experimentaci√≥n**:
- üìä Siempre comparar con un baseline simple (CNN desde cero)
- üìä Monitorear overfitting gap, no solo test accuracy
- üìä Considerar trade-offs: accuracy vs velocidad vs par√°metros
- üìä Probar m√∫ltiples arquitecturas antes de decidir

## Conclusiones

### 1. Las CNNs son el Est√°ndar para Visi√≥n por Computadora

La superioridad de las CNNs sobre las MLPs qued√≥ claramente demostrada:
- **CNN simple**: 69.37% test accuracy
- **Mejor MLP (TA8)**: 56.2% test accuracy
- **Mejora**: +13.17%

Esta mejora se logr√≥ con una arquitectura simple de solo 2 bloques convolucionales. CNNs m√°s profundas (ResNet, VGG, Inception) pueden alcanzar 90%+ en CIFAR-10.

### 2. Transfer Learning Requiere Ajuste Cuidadoso

El transfer learning no funcion√≥ bien "out of the box" debido al mismatch entre ImageNet y CIFAR-10. Sin embargo, con las configuraciones adecuadas (fine-tuning, data augmentation, clasificador m√°s complejo), se puede igualar o superar a la CNN simple.

**Cu√°ndo usar cada enfoque**:
- **CNN desde cero**: Dataset suficientemente grande, dominio espec√≠fico
- **Transfer Learning**: Pocos datos, dominio similar a ImageNet, tiempo limitado


### 3. Comparaciones

Nuestros resultados en contexto:

| Enfoque | Test Accuracy | Observaci√≥n |
|---------|---------------|-------------|
| **Baseline MLP (TA8)** | 56.2% | Mejor MLP con regularizaci√≥n |
| **Nuestra CNN simple** | 69.4% | 2 bloques conv |
| **Nuestro Transfer Learning** | 51.1% | Sin fine-tuning, mal configurado |

Hay margen significativo de mejora aplicando t√©cnicas m√°s avanzadas.

### 5. Reflexi√≥n Final

Esta tarea demostr√≥ que **la arquitectura importa tanto como los hiperpar√°metros**. En la TA8, optimizamos exhaustivamente MLPs y alcanzamos 56.2%. Con una CNN simple, sin optimizaci√≥n especial, superamos ese resultado en la primera iteraci√≥n (69.4%).

Esto ilustra un principio fundamental del deep learning: **usar la arquitectura correcta para el problema correcto es m√°s importante que optimizar una arquitectura incorrecta**.


---

**Recursos adicionales**:
- [CS231n: Convolutional Neural Networks](http://cs231n.stanford.edu/)
- [Transfer Learning Guide - Keras](https://keras.io/guides/transfer_learning/)
- [CIFAR-10 Benchmark](https://paperswithcode.com/sota/image-classification-on-cifar-10)

