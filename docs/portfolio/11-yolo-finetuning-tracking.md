# TA11 - YOLO Fine-tuning y Object Tracking: Detecci√≥n de Productos en Retail

## Resumen de la Tarea

Esta tarea exploramos **Object Detection con YOLOv8** y **Object Tracking** aplicados a un caso de uso real: detecci√≥n y seguimiento de frutas. El objetivo fue comprender c√≥mo adaptar modelos preentrenados de detecci√≥n de objetos a dominios espec√≠ficos mediante fine-tuning, y c√≥mo implementar tracking para seguir objetos en video.

### Metodolog√≠a

1. **Inferencia baseline**: YOLOv8 preentrenado en COCO (80 clases gen√©ricas)
2. **Dataset**: Fruit Detection con 6 clases de frutas (32,061 instancias)
3. **Fine-tuning**: Adaptar YOLOv8n al dominio espec√≠fico de frutas
4. **Evaluaci√≥n**: Comparamos antes y despu√©s
5. **Tracking**: Implementar seguimiento de productos en video con Norfair

## Contexto del Proyecto

Como parte de un equipo de Computer Vision en una cadena de supermercados tuvimos que construir un modelo que sea capaz de:

- ‚úÖ Detectar productos espec√≠ficos en estantes para control de inventario autom√°tico
- ‚úÖ Trackear productos en cintas transportadoras de checkout
- ‚úÖ Contar √≠tems para an√°lisis de ventas en tiempo real
- ‚úÖ Monitorear reposici√≥n de productos en tiempo real

**El problema**: YOLOv8 base (entrenado en COCO) NO detecta bien productos espec√≠ficos de grocery como frutas individuales, paquetes espec√≠ficos, etc. Necesitamos fine-tunear el modelo para mejorar la detecci√≥n.

## Implementaci√≥n y Resultados

### Parte 1: Inferencia con Modelo Base (COCO)

**Caracter√≠sticas del modelo base**:
- **Dataset**: COCO (80 clases gen√©ricas)
- **Arquitectura**: YOLOv8 nano 
- **Clases relevantes para grocery**: apple, orange, banana, carrot, bottle, cup, bowl
- **Limitaci√≥n**: Solo 7 clases gen√©ricas relacionadas con alimentos

#### Resultados de Inferencia Baseline

Probamos el modelo base en una imagen como si fuera una foto de la seccion de frutas y verduras de un supermercado:

![Detecci√≥n con modelo base COCO](11-imagenes/baseline-detection.png)

*Inferencia del modelo YOLOv8 base preentrenado en COCO aplicado a una imagen de productos de supermercado. El modelo detecta algunas frutas gen√©ricas (naranjas, manzanas) pero con baja confianza y varios falsos positivos como "br√≥coli" donde no hay. Esto demuestra la necesidad de fine-tuning para dominios espec√≠ficos.*

**Detecciones del modelo base**:
- Naranjas
- Br√≥coli
- Manzanas

**Problemas observados**:
- Muchas detecciones con confianza <0.3
- Detecta "br√≥coli" donde no hay 
- No reconoce otras frutas y verduras presentes en la foto

**Conclusi√≥n**: El modelo base de COCO no es suficiente, asi que necesitamos hacer fine-tuning.

### Parte 2: Preparaci√≥n del Dataset 

#### Caracter√≠sticas
- Total de im√°genes: 8,479
- Train: 7,108 im√°genes
- Validation: 914 im√°genes
- Test: 457 im√°genes
- Clases: 6 (Apple, Banana, Grape, Orange, Pineapple, Watermelon)
- Formato: YOLO (txt con coordenadas normalizadas)

#### Distribuci√≥n de Clases en Training Set

| Clase | Instancias | Porcentaje |
|-------|-----------|-----------|
| **Orange** | 13,938 | 43.5% |
| **Apple** | 6,070 | 18.9% |
| **Grape** | 6,027 | 18.8% |
| **Banana** | 2,971 | 9.3% |
| **Watermelon** | 1,683 | 5.2% |
| **Pineapple** | 1,372 | 4.3% |
| **TOTAL** | **32,061** | **100%** |

![Distribuci√≥n de clases en el dataset](11-imagenes/class-distribution.png)

*Distribuci√≥n de instancias por clase en el training set. Orange domina con 13,938 instancias (43.5%), mientras que Pineapple es la clase minoritaria con solo 1,372 instancias (4.3%). Este desbalance de 10:1 puede causar que el modelo tenga bias hacia la clase mayoritaria.*

**Observaciones sobre el desbalance**:
- Orange es la clase dominante (43.5%) ‚Üí el modelo ser√° mejor detectando naranjas
- Pineapple es la clase minoritaria (4.3%) ‚Üí mayor riesgo de errores

**Impacto del desbalance**:
- El modelo tender√° a predecir "Orange" con mayor frecuencia
- Pineapple y Watermelon pueden tener menor recall

#### Visualizaci√≥n de Ejemplos con Annotations

![Ejemplos del dataset con anotaciones](11-imagenes/training-samples.png)

*Ejemplos de im√°genes del training set con bounding boxes anotados. Se observan frutas en diferentes contextos, escalas e iluminaciones. Las anotaciones (cajas verdes con labels) son precisas y permiten al modelo aprender a detectar y clasificar correctamente cada tipo de fruta.*

Las im√°genes del dataset muestran:
- Frutas en diferentes contextos (estantes, manos, fondos variados)
- M√∫ltiples instancias por imagen (2-10 frutas t√≠picamente)
- Variedad de escalas (frutas cerca y lejos)
- Diferentes iluminaciones y √°ngulos
- Bounding boxes bien anotados

**Calidad del dataset**: Alta - anotaciones precisas y variedad suficiente para fine-tuning pero con desbalance de algunas clases frente a otras.

### Parte 3: Fine-tuning de YOLOv8

#### Par√°metros de configuraci√≥n

**Par√°metros clave**:
- **Modelo base**: YOLOv8n (3M par√°metros)
- **Optimizer**: SGD 
- **Learning rate**: 0.01 inicial, decay a 0.01 final
- **Augmentation**: Autom√°tico (mosaic, flip, hsv, scale)

#### Resultados del Fine-tuning

**M√©tricas finales en validation set**:

| M√©trica | Valor | Interpretaci√≥n |
|---------|-------|----------------|
| **mAP@0.5** | 0.382 | Precisi√≥n promedio con IoU‚â•0.5 |
| **mAP@0.5:0.95** | 0.247 | Precisi√≥n promedio con IoU de 0.5 a 0.95 |
| **Precision** | 0.508 | 50.8% de detecciones son correctas |
| **Recall** | 0.379 | 37.9% de objetos reales fueron detectados |

**M√©tricas por clase**:

| Clase | mAP@0.5 | Observaci√≥n |
|-------|---------|-------------|
| **Watermelon** | 0.338 | Mejor clase detectada |
| **Apple** | 0.259 | - |
| **Pineapple** | 0.239 | Menos datos  aceptable |
| **Banana** | 0.239 | Menos datos  aceptable |
| **Orange** | 0.223 | muchos datos pero se confunde mas |
| **Grape** | 0.185 | Peor clase (peque√±a y en agrupaciones) |

**Observaciones del entrenamiento**:
- No hay overfitting severo (train y val similares)
- mAP@0.5:0.95 bajo (0.247) indica que las detecciones no son muy precisas en localizaci√≥n

![Curvas de entrenamiento](11-imagenes/training-results.png)

*Resultados del entrenamiento durante 30 √©pocas. Los gr√°ficos muestran la evoluci√≥n de m√©tricas clave como mAP, precision, recall y loss tanto en training como en validation. Se observa convergencia estable sin signos de overfitting severo.*

### Parte 4: Comparaci√≥n Base vs Fine-tuned

#### An√°lisis Cualitativo

Comparamos ambos modelos en 2 im√°genes del validation set:

![Comparaci√≥n 1: Manzana](11-imagenes/comparison-1.png)

*Comparaci√≥n en imagen de manzana. Izquierda: Modelo base (COCO) detecta "apple". Derecha: Modelo fine-tuned detecta "Apple". Ambos funcionan correctamente en este caso.*

![Comparaci√≥n 2: Uvas](11-imagenes/comparison-2.png)

*Comparaci√≥n en imagen de uvas. Izquierda: Modelo base confunde las uvas con "vase" (florero). Derecha: Modelo fine-tuned detecta correctamente "Grape". El fine-tuning resuelve este error.*



**Imagen 1 - Manzana**:
- Base (COCO): 1 detecci√≥n ‚Üí "apple"
- Fine-tuned: 1 detecci√≥n ‚Üí "Apple"
- Resultado: Empate - ambos detectan correctamente

**Imagen 2 - Uvas**:
- Base (COCO): 1 detecci√≥n ‚Üí "vase" (confundi√≥ uvas con florero)
- Fine-tuned: 1 detecci√≥n ‚Üí "Grape"
- Resultado: Fine-tuned gana - detecta correctamente


#### An√°lisis Cuantitativo de Errores

Analizamos 10 im√°genes del validation set calculando True Positives (TP), False Positives (FP) y False Negatives (FN):

**Resultados comparativos**:

| Modelo | TP | FP | FN | Precision | Recall | F1-Score |
|--------|----|----|----|-----------| -------|----------|
| **Base (COCO)** | 0 | 4 | 3 | 0.000 | 0.000 | 0.000 |
| **Fine-tuned** | 2 | 1 | 1 | 0.667 | 0.667 | 0.667 |
| **Mejora** | +2 | -3 | -2 | **+0.667** | **+0.667** | **+0.667** |

**Interpretaci√≥n**:

**Modelo base no funciona en este dominio:**
- 0 True Positives ‚Üí no detect√≥ ninguna fruta correctamente
- 4 False Positives ‚Üí detect√≥ cosas que no son frutas
- 3 False Negatives ‚Üí se perdi√≥ 3 frutas reales
- F1-Score = 0.000 ‚Üí completamente inservible

**Fine-tuned mejora dram√°ticamente:**
- 2 True Positives ‚Üí detect√≥ 2 frutas correctamente
- Solo 1 False Positive ‚Üí menos errores
- Solo 1 False Negative ‚Üí detecta m√°s frutas
- F1-Score = 0.667 

**Mejora absoluta:**
- +0.667 en Precision: De 0% a 66.7%
- +0.667 en Recall: De 0% a 66.7%
- +0.667 en F1-Score: De 0% a 66.7%

![Comparaci√≥n de m√©tricas](11-imagenes/metrics-comparison.png)

*Gr√°fico comparativo de m√©tricas entre modelo base y fine-tuned. El modelo base tiene Precision, Recall y F1-Score de 0.000 (completamente in√∫til), mientras que el fine-tuned alcanza 0.667 en las tres m√©tricas, demostrando la efectividad del fine-tuning.*

### Parte 5: Object Tracking en Video

#### Configuraci√≥n del Tracker

Implementamos tracking con **Norfair**, una librer√≠a especializada en object tracking:

**Par√°metros clave**:
- **distance_function**: `mean_euclidean` calcula distancia entre centros de bounding boxes
- **distance_threshold=100**: Si distancia >100 p√≠xeles, considera que es un objeto diferente
- **hit_counter_max=30**: Si un objeto no se detecta por 30 frames (~1 segundo), se elimina el track
- **initialization_delay=2**: Necesita 2 detecciones consecutivas para crear un track nuevo (reduce falsos positivos)

#### Procesamiento del Video

**Caracter√≠sticas del video**:
- Duraci√≥n: 11.4 segundos
- Frames: 343 frames
- FPS: 29.97
- Resoluci√≥n: 768√ó432
- Contenido: Frutas girando

#### Resultados del Tracking

**Estad√≠sticas generales**:
- Total productos trackeados: 13 tracks
- Duraci√≥n promedio: 75.3 frames (2.5 segundos)
- Duraci√≥n m√°xima: 341 frames (11.4 segundos) - Track ID 1 (Orange)
- Duraci√≥n m√≠nima: 4 frames (0.1 segundos) - Track ID 2 (Apple)

**Productos por clase**:
- Apple: 6 tracks (46.2%)
- Orange: 4 tracks (30.8%)
- Banana: 3 tracks (23.1%)

#### Ejemplo Visual de Tracking en Acci√≥n

![Video Tracking - Frame 150](11-imagenes/tracking-frame-150.png)

*Frame 150 del video procesado mostrando el tracking en acci√≥n. Se observan 3 productos simult√°neamente: Banana (ID6, caja morada), Apple (ID9, caja amarilla) y Orange (ID11, caja azul). Cada objeto mantiene su ID √∫nico a lo largo del video, permitiendo conteo preciso y an√°lisis de trayectorias.*

**Observaciones del frame**:
- IDs persistentes: Cada fruta mantiene su ID √∫nico (6, 9, 11)
- Bounding boxes precisos: Las cajas delimitan correctamente cada objeto
- Colores distintivos: Cada track tiene color √∫nico para f√°cil identificaci√≥n visual
- Labels claros: Formato "ID{n√∫mero}: {clase}" facilita interpretaci√≥n
- M√∫ltiples objetos: El sistema maneja 3 frutas simult√°neamente sin confusi√≥n

## Reflexi√≥n y An√°lisis

### 1. Fine-tuning es Esencial para Dominios Espec√≠ficos

Un modelo preentrenado en COCO (80 clases gen√©ricas) no es tan util para detecci√≥n de productos espec√≠ficos, pero sirve com base, y no tener que crear el modelo entero, ya qeu crearlo y entrenarlo llevaria mucho tiempo.


### 2. Desbalance de Clases Afecta Rendimiento

Orange por ejemplo tiene 10 veces m√°s datos que Pineapple, pero su efectividad es menor.
esto se debe principalmente a que Pineapple tiene forma distintiva, mas f√°cil de aprender, Orange en cambio la puede  confundir con Apple (ambas redondas y similares) y ademas tiene m√°s variabilidad (diferentes tama√±os, colores, contextos)

M√°s datos no siempre significa que el rendimiento vaya a ser mejor. La distintividad de la clase importan m√°s que la cantidad.


### 3. Aplicaciones Reales de Negocio

Este problema es uno de los que m√°s me ha gustado ya que tiene un impacto y aplicaci√≥n real de negocio y se puede llevar a infinitos √°mbitos de aplicaci√≥n:

#### Manufactura & Log√≠stica:
- Control de calidad: Detectar defectos en productos en l√≠nea de producci√≥n
- Tracking de paquetes: Seguir paquetes en centros de distribuci√≥n
- Conteo autom√°tico: Contar productos en pallets sin intervenci√≥n humana

#### Seguridad & Vigilancia:
- Conteo de personas: Medir aforo en tiendas, eventos
- Parking inteligente: Detectar espacios libres en estacionamientos
- Detecci√≥n de anomal√≠as: Identificar comportamientos sospechosos

#### Salud & Medicina:
- Conteo de c√©lulas: Detectar y contar c√©lulas en microscop√≠a
- Control de medicamentos: Verificar que pastillas correctas est√©n en blister
- Tracking de instrumental: Seguir instrumentos quir√∫rgicos en sala de operaciones

#### Valor de negocio:
- ROI alto: Reducci√≥n de costos laborales
- Eficiencia: Procesos autom√°ticos 24/7
- Escalabilidad: Un modelo puede replicarse en m√∫ltiples ubicaciones
- Precisi√≥n: Menos errores humanos en conteo y clasificaci√≥n

---

## Preguntas sobre la Tarea

### Sobre el Modelo

**¬øCu√°l fue la mejora m√°s significativa del fine-tuning?**

La reducci√≥n de falsos positivos. El modelo base detectaba objetos incorrectos (como "br√≥coli" o "person" donde no hab√≠a), mientras que el fine-tuned elimin√≥ casi todos estos errores. La mejora en F1-Score de 0.0 a 0.667 refleja esto.

**¬øEl modelo base (COCO) era completamente in√∫til o ten√≠a algo de valor?**

Ten√≠a valor como punto de partida. Detectaba algunas frutas gen√©ricas correctamente (manzanas, naranjas), pero con baja confianza y muchos errores. Lo importante es que ya ten√≠a conocimiento sobre detecci√≥n de objetos, solo necesitaba especializaci√≥n.

**Si tuvieras que hacer fine-tuning para otro dominio (ej: piezas industriales), ¬øqu√© aprender√≠as de esta experiencia?**

Tres lecciones clave: 1) La calidad de las anotaciones es cr√≠tica, 2) No necesitas millones de im√°genes si las que tienes son buenas, 3) Monitorear m√©tricas por clase, no solo globales, para identificar d√≥nde necesitas m√°s datos.

### Sobre los Datos

**¬ø8,479 im√°genes es mucho o poco para fine-tuning? ¬øPor qu√© funcion√≥ usar solo 25%?**

Es suficiente para fine-tuning (no para entrenar desde cero). Funcion√≥ con 25% porque el modelo base ya conoc√≠a features generales de objetos. Solo necesitaba aprender las caracter√≠sticas espec√≠ficas de estas 6 frutas.

**¬øLa calidad de las anotaciones afect√≥ los resultados? ¬øC√≥mo lo sabes?**

S√≠, definitivamente. Los bounding boxes estaban bien ajustados y las clases correctamente etiquetadas. Lo sabemos porque el modelo convergi√≥ r√°pido y las detecciones son precisas en localizaci√≥n, no solo en clasificaci√≥n.

**Si pudieras agregar 1,000 im√°genes m√°s, ¬øde qu√© tipo ser√≠an?**

Principalmente de Grape (la peor clase) y Pineapple (la qu tenia menos imagenes). Tambi√©n agregar√≠a casos dif√≠ciles: frutas parcialmente ocultas, iluminaci√≥n extrema, √°ngulos inusuales, y m√∫ltiples frutas muy juntas.

### Sobre el Tracking

**¬øQu√© fue m√°s importante para un buen tracking: el modelo o los par√°metros del tracker?**

El modelo. Si el detector falla, el tracker no puede hacer nada.

**¬øNorfair (IoU-based) es suficiente o necesitas algo m√°s sofisticado como DeepSORT?**

Para este caso (frutas girando, sin oclusiones severas) Norfair funciono bastante bien

**¬øLos filtros de Kalman mejoraron la estabilidad del tracking? ¬øEn qu√© situaciones?**

Si, es util cuando la confianza cae temporalmente.

**¬øEn qu√© escenarios fallar√≠a este sistema de tracking?**

- Objetos id√©nticos intercambiando posiciones
- Movimientos muy r√°pidos
- Entrada/salida frecuente de objetos del cuadro

### Sobre el Deployment

**¬øEste sistema podr√≠a correr en tiempo real? ¬øQu√© FPS necesitar√≠as?**
No estoy del todo seguro, pensaria que si, pero dependiendo de que tan tiempo real se tenga que considerar ya que la deteccion por frames no es del todo tan rapida, si el modelo de negocio admite cierto delay no habria problemas.

**¬øQu√© optimizaciones har√≠as para producci√≥n?**

Usaria la resoluci√≥n m√°s baja  aceptable
Procesar cada N frames (si puedo tener cierto delay)

**¬øC√≥mo manejar√≠as casos extremos?**

- Oclusiones: Aumentar `hit_counter_max` para mantener tracks m√°s tiempo
- Iluminaci√≥n: Data augmentation agresivo en brightness/contrast durante training
- √Ångulos raros: Incluir esos casos en dataset de entrenamiento


### Trade-offs y Decisiones

**Identifica 3 trade-offs clave que encontraste**

1. **Speed vs Accuracy**: Usar img_size=320 en vez de 640 
2. **Epochs vs Tiempo**: 30 √©pocas en 4 minutos vs 100 √©pocas en 15 minutos ‚Üí diferencia de solo +3% mAP
3. **Threshold de confianza**: conf=0.3 ‚Üí m√°s detecciones pero m√°s FPs; conf=0.5 ‚Üí menos FPs pero m√°s FNs

**Si tuvieras que explicar este proyecto a un stakeholder no-t√©cnico, ¬øqu√© 3 puntos destacar√≠as?**

1. **El problema**: Los sistemas gen√©ricos no funcionan para casos espec√≠ficos. Necesit√°bamos un modelo especializado en detectar frutas.
2. **La soluci√≥n**: Adaptamos un modelo existente con nuestros datos, logrando 67% de precisi√≥n en poco tiempo de entrenamiento.
3. **El valor**: Sistema puede contar productos autom√°ticamente en video, eliminando conteo manual y reduciendo errores humanos. "Deployable" en tiendas reales.

---

## üìö Recursos Adicionales

- [Ultralytics YOLOv8 Documentation](https://docs.ultralytics.com/)
- [YOLOv8 Training Guide](https://docs.ultralytics.com/modes/train/)
- [Fruit Detection Dataset en Kaggle](https://www.kaggle.com/datasets/lakshaytyagi01/fruit-detection)
- [Object Detection Datasets on Kaggle](https://www.kaggle.com/datasets?search=object+detection)
- [Norfair Tracking Library](https://github.com/tryolabs/norfair)
- [SORT Tracking Paper](https://arxiv.org/abs/1602.00763)
- [DeepSORT Paper](https://arxiv.org/abs/1703.07402)
- [ByteTrack Paper](https://arxiv.org/abs/2110.06864)


